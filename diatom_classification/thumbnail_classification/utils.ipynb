{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import errno\n",
    "\n",
    "import csv\n",
    "\n",
    "def get_dataset(dataset_folder, ids=False):\n",
    "    result = {}\n",
    "    x_set = []\n",
    "    y_set = []\n",
    "    print(\"Retrieving dataset from:\", dataset_folder)\n",
    "    taxons_dirs = next(os.walk(dataset_folder))[1]\n",
    "    n_taxons = len(taxons_dirs)\n",
    "    disp_progress = display(\"0/\"+str(n_taxons),display_id=True)\n",
    "    for i, taxon in enumerate(taxons_dirs):\n",
    "        taxon_id = taxon\n",
    "        path = join(dataset_folder, taxon)\n",
    "        files = [f for f in os.listdir(path) if isfile(join(path, f))]\n",
    "        for file in files:\n",
    "            x_set.append(join(path, file))\n",
    "            y_set.append(taxon_id)\n",
    "            result.setdefault(taxon_id, []).append(join(path, file))\n",
    "        disp_progress.update(str(i+1)+\"/\"+str(n_taxons))\n",
    "    return np.array(x_set), np.array(y_set), result\n",
    "\n",
    "def get_last_epoch(log_file):\n",
    "    if os.path.exists(log_file):\n",
    "        csv_reader = csv.reader(open(log_file), delimiter=',')\n",
    "        return int(list(csv_reader)[-1][0])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def save_model(model, root):\n",
    "    model_path = os.path.join(root, \"model.json\")\n",
    "    weights_path = os.path.join(root, \"model.h5\")\n",
    "    check_dirs(model_path)\n",
    "\n",
    "    model_json = model.to_json()\n",
    "    with open(model_path, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(weights_path)\n",
    "\n",
    "    print(\"Saved model to\", model_path)\n",
    "    print(\"Saved weights to\", weights_path)\n",
    "\n",
    "def get_taxa_list(list_path):\n",
    "    taxa_list = []\n",
    "    with open(list_path, newline='') as csvfile: \n",
    "        csv_reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "        for row in csv_reader:\n",
    "            taxa_list.extend(row)\n",
    "    return taxa_list\n",
    "\n",
    "def balance_dataset(X_train, y_train, max_samples=None):\n",
    "    train_dict = {}\n",
    "    for file, label in zip(X_train, y_train):\n",
    "        train_dict.setdefault(label, []).append(file)\n",
    "    if max_samples is None: max_samples = np.max([len(train_dict[taxon_id]) for taxon_id in train_dict])\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for taxon_id in train_dict:\n",
    "        ratio = np.ceil(max_samples/len(train_dict[taxon_id]))\n",
    "        tmp = np.repeat(train_dict[taxon_id], ratio)\n",
    "        np.random.shuffle(tmp)\n",
    "        train_dict[taxon_id] = tmp[0:max_samples]\n",
    "        X_train.extend(tmp[0:max_samples])\n",
    "        y_train.extend([taxon_id]*max_samples)\n",
    "    print(\"Balanced to\", max_samples, \"samples per class!\")\n",
    "    return X_train, y_train, max_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_clipped_zoom(img, zoom_factor):\n",
    "    \"\"\"\n",
    "    Center zoom in/out of the given image and returning an enlarged/shrinked view of \n",
    "    the image without changing dimensions\n",
    "    Args:\n",
    "        img : Image array\n",
    "        zoom_factor : amount of zoom as a ratio (0 to Inf)\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2] # It's also the final desired shape\n",
    "    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n",
    "\n",
    "    ### Crop only the part that will remain in the result (more efficient)\n",
    "    # Centered bbox of the final desired size in resized (larger/smaller) image coordinates\n",
    "    y1, x1 = max(0, new_height - height) // 2, max(0, new_width - width) // 2\n",
    "    y2, x2 = y1 + height, x1 + width\n",
    "    bbox = np.array([y1,x1,y2,x2])\n",
    "    # Map back to original image coordinates\n",
    "    bbox = (bbox / zoom_factor).astype(np.int)\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Handle padding when downscaling\n",
    "    resize_height, resize_width = min(new_height, height), min(new_width, width)\n",
    "    pad_height1, pad_width1 = (height - resize_height) // 2, (width - resize_width) //2\n",
    "    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n",
    "    pad_spec = [(pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n",
    "\n",
    "    result = cv2.resize(cropped_img, (resize_width, resize_height))\n",
    "    result = np.pad(result, pad_spec, mode='edge')\n",
    "    assert result.shape[0] == height and result.shape[1] == width\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
