{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import errno\n",
    "import csv\n",
    "\n",
    "def get_dataset(dataset_folder, ids=False):\n",
    "    result = {}\n",
    "    x_set = []\n",
    "    y_set = []\n",
    "    taxons_dirs = next(os.walk(dataset_folder))[1]\n",
    "    n_taxons = len(taxons_dirs)\n",
    "    disp_progress = display(\"0/\"+str(n_taxons),display_id=True)\n",
    "    for i, taxon in enumerate(taxons_dirs):\n",
    "        taxon_id = taxon\n",
    "        path = join(dataset_folder, taxon)\n",
    "        files = [f for f in os.listdir(path) if isfile(join(path, f))]\n",
    "        for file in files:\n",
    "            x_set.append(join(path, file))\n",
    "            y_set.append(taxon_id)\n",
    "            result.setdefault(taxon_id, []).append(join(path, file))\n",
    "        disp_progress.update(str(i+1)+\"/\"+str(n_taxons))\n",
    "    return x_set, y_set, result\n",
    "\n",
    "def get_last_epoch(log_file):\n",
    "    if os.path.exists(log_file):\n",
    "        csv_reader = csv.reader(open(log_file), delimiter=',')\n",
    "        return int(list(csv_reader)[-1][0])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def save_model(model, root):\n",
    "    model_path = os.path.join(root, \"model.json\")\n",
    "    weights_path = os.path.join(root, \"model.h5\")\n",
    "    check_dirs(model_path)\n",
    "\n",
    "    model_json = model.to_json()\n",
    "    with open(model_path, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(weights_path)\n",
    "\n",
    "    print(\"Saved model to\", model_path)\n",
    "    print(\"Saved weights to\", weights_path)\n",
    "\n",
    "def get_taxa_list(list_path):\n",
    "    taxa_list = []\n",
    "    with open(list_path, newline='') as csvfile: \n",
    "        csv_reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "        for row in csv_reader:\n",
    "            taxa_list.extend(row)\n",
    "    return taxa_list\n",
    "\n",
    "def balance_dataset(X_train, y_train, max_samples=None):\n",
    "    train_dict = {}\n",
    "    for file, label in zip(X_train, y_train):\n",
    "        train_dict.setdefault(label, []).append(file)\n",
    "    if max_samples is None: max_samples = np.max([len(train_dict[taxon_id]) for taxon_id in train_dict])\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for taxon_id in train_dict:\n",
    "        ratio = np.ceil(max_samples/len(train_dict[taxon_id]))\n",
    "        tmp = np.repeat(train_dict[taxon_id], ratio)\n",
    "        np.random.shuffle(tmp)\n",
    "        train_dict[taxon_id] = tmp[0:max_samples]\n",
    "        X_train.extend(tmp[0:max_samples])\n",
    "        y_train.extend([taxon_id]*max_samples)\n",
    "    print(\"Balanced to\", max_samples, \"samples per class!\")\n",
    "    return X_train, y_train, max_samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
