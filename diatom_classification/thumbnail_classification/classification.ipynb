{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import math, random\n",
    "import time, datetime, sys, os, shutil\n",
    "import operator\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "print(tf.config.experimental.list_physical_devices())\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "%run ./variables.ipynb\n",
    "%run ./utils.ipynb\n",
    "%run ../utils/data_utils.ipynb\n",
    "\n",
    "id_map = get_selected_taxons(SELECTED_TAXONS)\n",
    "id_map_inv = get_selected_taxons(SELECTED_TAXONS, inv=True)\n",
    "n_classes = len(list(id_map.keys()))\n",
    "check_dirs(SAVED_MODELS_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing panda arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'38/38'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'38/38'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test length: 753 - n classes: 38\n",
      "Test length: 84 - n classes: 38\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, _ = get_dataset(TRAIN_DATASET_PATH, ids=False)\n",
    "X_test, y_test, _ = get_dataset(TEST_DATASET_PATH, ids=False)\n",
    "\n",
    "print(\"Test length:\", len(X_train), \"- n classes:\", len(np.unique(y_train)))\n",
    "print(\"Test length:\", len(X_test), \"- n classes:\", len(np.unique(y_test)))\n",
    "\n",
    "# Balance dataset\n",
    "#X_train, y_train, max_samples = balance_dataset(X_train, y_train, max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753 84\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>png_path</th>\n",
       "      <th>taxon_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/nvme-storage/pfauregi/training/thumbails/...</td>\n",
       "      <td>Nitzschia_hantzschiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/nvme-storage/pfauregi/training/thumbails/...</td>\n",
       "      <td>Encyonema_silesiacum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/nvme-storage/pfauregi/training/thumbails/...</td>\n",
       "      <td>Denticula_tenuis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/nvme-storage/pfauregi/training/thumbails/...</td>\n",
       "      <td>Diatoma_mesodon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/nvme-storage/pfauregi/training/thumbails/...</td>\n",
       "      <td>Nitzschia_dissipata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            png_path                taxon_id\n",
       "0  /mnt/nvme-storage/pfauregi/training/thumbails/...  Nitzschia_hantzschiana\n",
       "1  /mnt/nvme-storage/pfauregi/training/thumbails/...    Encyonema_silesiacum\n",
       "2  /mnt/nvme-storage/pfauregi/training/thumbails/...        Denticula_tenuis\n",
       "3  /mnt/nvme-storage/pfauregi/training/thumbails/...         Diatoma_mesodon\n",
       "4  /mnt/nvme-storage/pfauregi/training/thumbails/...     Nitzschia_dissipata"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = {'png_path':  X_train, 'taxon_id': y_train}\n",
    "data_test = {'png_path':  X_test, 'taxon_id': y_test}\n",
    "\n",
    "df_train = pd.DataFrame(data_train, columns = ['png_path', 'taxon_id'])\n",
    "df_test = pd.DataFrame(data_test, columns = ['png_path', 'taxon_id'])\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Prtining some infos\n",
    "print(len(df_train), len(df_test))\n",
    "df_train.head()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                         rotation_range=20, \n",
    "                         brightness_range=[0.8,1.2], \n",
    "                         horizontal_flip=True, \n",
    "                         vertical_flip=True,\n",
    "                         fill_mode='nearest',\n",
    "                         width_shift_range=10,\n",
    "                         height_shift_range=10,\n",
    "                         zoom_range=0.2,\n",
    "                         data_format=\"channels_last\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                         data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 753 validated image filenames belonging to 38 classes.\n",
      "Found 84 validated image filenames belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "#classes_array = np.unique(y_train)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=df_train,\n",
    "        x_col='png_path',\n",
    "        y_col='taxon_id',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        #classes=classes_array,\n",
    "        class_mode='categorical')\n",
    "val_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=df_test,\n",
    "        x_col='png_path',\n",
    "        y_col='taxon_id',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        classes=train_generator.class_indices,\n",
    "        class_mode='categorical')\n",
    "\n",
    "train_spe = train_generator.samples // BATCH_SIZE\n",
    "val_spe = val_generator.samples // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = train_generator.class_indices\n",
    "f = open(os.path.join(SAVED_MODELS_ROOT, 'model_id_map.csv'), 'w')\n",
    "with f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"taxon\", \"id\"])\n",
    "    for taxon in class_indices:\n",
    "        writer.writerow([taxon, class_indices[taxon]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "stop = False\n",
    "for batch in train_generator:\n",
    "    images = batch[0]\n",
    "    labels = batch[1]\n",
    "    for i in range(images.shape[0]):\n",
    "        print(np.argmax(labels[i]))\n",
    "        image = (images[i,:,:,:]*255).astype('uint8')\n",
    "        #print(image)\n",
    "        display(Image.fromarray(image))\n",
    "        i+=1\n",
    "        if i>=1:\n",
    "            stop = True\n",
    "            break\n",
    "    if stop: pass;\n",
    "    #display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model desgin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching base model\n",
    "input_tensor = Input(shape=(256, 256, 3))\n",
    "#base_model = InceptionV3(weights='imagenet', input_tensor=input_tensor, include_top=False)\n",
    "base_model = Xception(include_top=False, weights='imagenet', input_tensor=input_tensor, pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model for specifiv case\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "out = Dense(len(train_generator.class_indices.keys()), activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting tensorboard\n",
    "check_dirs(LOG_DIR)\n",
    "delete_all_files_in_folder(LOG_DIR)\n",
    "log_dir = LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file=os.path.join(SAVED_MODELS_ROOT, \"model.log\")\n",
    "os.remove(log_file)\n",
    "csv_logger = CSVLogger(log_file, append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, decay=0, momentum=0, nesterov=False)\n",
    "optimizer = sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New layers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epochs composed of 23 batches (steps) of 32 images.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 23 steps, validate for 2 steps\n",
      "Epoch 1/5\n",
      " 1/23 [>.............................] - ETA: 1:34 - loss: 3.5701 - accuracy: 0.0312WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.175109). Check your callbacks.\n",
      "23/23 [==============================] - 13s 577ms/step - loss: 3.6202 - accuracy: 0.0499 - val_loss: 3.6204 - val_accuracy: 0.0469\n",
      "Epoch 2/5\n",
      "23/23 [==============================] - 10s 435ms/step - loss: 3.5669 - accuracy: 0.0874 - val_loss: 3.5913 - val_accuracy: 0.0469\n",
      "Epoch 3/5\n",
      "23/23 [==============================] - 10s 433ms/step - loss: 3.5118 - accuracy: 0.1650 - val_loss: 3.5661 - val_accuracy: 0.0781\n",
      "Epoch 4/5\n",
      "23/23 [==============================] - 10s 433ms/step - loss: 3.4632 - accuracy: 0.2136 - val_loss: 3.5410 - val_accuracy: 0.0938\n",
      "Epoch 5/5\n",
      "23/23 [==============================] - 10s 433ms/step - loss: 3.4159 - accuracy: 0.2732 - val_loss: 3.5171 - val_accuracy: 0.0938\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "last_epoch = get_last_epoch(log_file)\n",
    "\n",
    "print(n_epochs, \"epochs composed of\", train_spe, \"batches (steps) of\", BATCH_SIZE, \"images.\")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_generator, \n",
    "          epochs=last_epoch+n_epochs, \n",
    "          steps_per_epoch=train_spe,\n",
    "          use_multiprocessing=False, \n",
    "          validation_data=val_generator,\n",
    "          validation_steps=val_spe,\n",
    "          callbacks=[tensorboard_callback, csv_logger],\n",
    "          initial_epoch=last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 epochs composed of 23 batches (steps) of 32 images.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 23 steps, validate for 2 steps\n",
      "Epoch 5/44\n",
      "23/23 [==============================] - 13s 570ms/step - loss: 3.0754 - accuracy: 0.2580 - val_loss: 3.3005 - val_accuracy: 0.1719\n",
      "Epoch 6/44\n",
      "23/23 [==============================] - 10s 451ms/step - loss: 2.7112 - accuracy: 0.3689 - val_loss: 3.0045 - val_accuracy: 0.2812\n",
      "Epoch 7/44\n",
      "23/23 [==============================] - 10s 450ms/step - loss: 2.3380 - accuracy: 0.5257 - val_loss: 2.7297 - val_accuracy: 0.3750\n",
      "Epoch 8/44\n",
      "23/23 [==============================] - 10s 455ms/step - loss: 2.0184 - accuracy: 0.6644 - val_loss: 2.4394 - val_accuracy: 0.4219\n",
      "Epoch 9/44\n",
      "23/23 [==============================] - 10s 453ms/step - loss: 1.7401 - accuracy: 0.7531 - val_loss: 2.1527 - val_accuracy: 0.4844\n",
      "Epoch 10/44\n",
      "23/23 [==============================] - 10s 453ms/step - loss: 1.4643 - accuracy: 0.8155 - val_loss: 1.8553 - val_accuracy: 0.5938\n",
      "Epoch 11/44\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 1.1687 - accuracy: 0.8752 - val_loss: 1.5646 - val_accuracy: 0.6875\n",
      "Epoch 12/44\n",
      "23/23 [==============================] - 10s 450ms/step - loss: 0.9919 - accuracy: 0.8904 - val_loss: 1.2888 - val_accuracy: 0.8281\n",
      "Epoch 13/44\n",
      "23/23 [==============================] - 10s 452ms/step - loss: 0.7975 - accuracy: 0.9112 - val_loss: 1.0555 - val_accuracy: 0.8438\n",
      "Epoch 14/44\n",
      "23/23 [==============================] - 10s 447ms/step - loss: 0.6531 - accuracy: 0.9265 - val_loss: 0.8789 - val_accuracy: 0.8594\n",
      "Epoch 15/44\n",
      "23/23 [==============================] - 10s 452ms/step - loss: 0.5437 - accuracy: 0.9348 - val_loss: 0.7372 - val_accuracy: 0.8750\n",
      "Epoch 16/44\n",
      "23/23 [==============================] - 10s 447ms/step - loss: 0.4702 - accuracy: 0.9390 - val_loss: 0.6129 - val_accuracy: 0.8906\n",
      "Epoch 17/44\n",
      "23/23 [==============================] - 10s 450ms/step - loss: 0.4113 - accuracy: 0.9515 - val_loss: 0.5283 - val_accuracy: 0.9219\n",
      "Epoch 18/44\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.3626 - accuracy: 0.9487 - val_loss: 0.4865 - val_accuracy: 0.9375\n",
      "Epoch 19/44\n",
      "23/23 [==============================] - 11s 459ms/step - loss: 0.3003 - accuracy: 0.9633 - val_loss: 0.4329 - val_accuracy: 0.9219\n",
      "Epoch 20/44\n",
      "23/23 [==============================] - 10s 452ms/step - loss: 0.2825 - accuracy: 0.9598 - val_loss: 0.4049 - val_accuracy: 0.9375\n",
      "Epoch 21/44\n",
      "23/23 [==============================] - 10s 452ms/step - loss: 0.2567 - accuracy: 0.9612 - val_loss: 0.3540 - val_accuracy: 0.9531\n",
      "Epoch 22/44\n",
      "23/23 [==============================] - 10s 451ms/step - loss: 0.2196 - accuracy: 0.9709 - val_loss: 0.3242 - val_accuracy: 0.9375\n",
      "Epoch 23/44\n",
      "23/23 [==============================] - 10s 451ms/step - loss: 0.1968 - accuracy: 0.9806 - val_loss: 0.2997 - val_accuracy: 0.9375\n",
      "Epoch 24/44\n",
      "23/23 [==============================] - 10s 450ms/step - loss: 0.1869 - accuracy: 0.9792 - val_loss: 0.2835 - val_accuracy: 0.9531\n",
      "Epoch 25/44\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.1649 - accuracy: 0.9820 - val_loss: 0.2958 - val_accuracy: 0.9375\n",
      "Epoch 26/44\n",
      "23/23 [==============================] - 10s 447ms/step - loss: 0.1531 - accuracy: 0.9820 - val_loss: 0.2488 - val_accuracy: 0.9531\n",
      "Epoch 27/44\n",
      "23/23 [==============================] - 10s 453ms/step - loss: 0.1441 - accuracy: 0.9806 - val_loss: 0.2519 - val_accuracy: 0.9531\n",
      "Epoch 28/44\n",
      "23/23 [==============================] - 10s 450ms/step - loss: 0.1306 - accuracy: 0.9861 - val_loss: 0.2477 - val_accuracy: 0.9531\n",
      "Epoch 29/44\n",
      "23/23 [==============================] - 10s 455ms/step - loss: 0.1306 - accuracy: 0.9834 - val_loss: 0.2266 - val_accuracy: 0.9531\n",
      "Epoch 30/44\n",
      "23/23 [==============================] - 10s 452ms/step - loss: 0.1218 - accuracy: 0.9875 - val_loss: 0.2436 - val_accuracy: 0.9219\n",
      "Epoch 31/44\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.1082 - accuracy: 0.9875 - val_loss: 0.2280 - val_accuracy: 0.9375\n",
      "Epoch 32/44\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.1130 - accuracy: 0.9806 - val_loss: 0.2145 - val_accuracy: 0.9375\n",
      "Epoch 33/44\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.1012 - accuracy: 0.9834 - val_loss: 0.1953 - val_accuracy: 0.9688\n",
      "Epoch 34/44\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.0883 - accuracy: 0.9945 - val_loss: 0.1922 - val_accuracy: 0.9531\n",
      "Epoch 35/44\n",
      "23/23 [==============================] - 10s 451ms/step - loss: 0.0885 - accuracy: 0.9889 - val_loss: 0.1770 - val_accuracy: 0.9531\n",
      "Epoch 36/44\n",
      "23/23 [==============================] - 10s 449ms/step - loss: 0.0870 - accuracy: 0.9903 - val_loss: 0.1607 - val_accuracy: 0.9688\n",
      "Epoch 37/44\n",
      "23/23 [==============================] - 10s 452ms/step - loss: 0.0820 - accuracy: 0.9889 - val_loss: 0.1449 - val_accuracy: 0.9844\n",
      "Epoch 38/44\n",
      "23/23 [==============================] - 10s 447ms/step - loss: 0.0760 - accuracy: 0.9917 - val_loss: 0.1506 - val_accuracy: 0.9688\n",
      "Epoch 39/44\n",
      "23/23 [==============================] - 10s 450ms/step - loss: 0.0737 - accuracy: 0.9875 - val_loss: 0.1566 - val_accuracy: 0.9531\n",
      "Epoch 40/44\n",
      "23/23 [==============================] - 10s 450ms/step - loss: 0.0668 - accuracy: 0.9958 - val_loss: 0.1430 - val_accuracy: 0.9688\n",
      "Epoch 41/44\n",
      "23/23 [==============================] - 10s 452ms/step - loss: 0.0567 - accuracy: 0.9986 - val_loss: 0.1039 - val_accuracy: 1.0000\n",
      "Epoch 42/44\n",
      "23/23 [==============================] - 10s 453ms/step - loss: 0.0594 - accuracy: 0.9903 - val_loss: 0.1243 - val_accuracy: 0.9844\n",
      "Epoch 43/44\n",
      "23/23 [==============================] - 10s 452ms/step - loss: 0.0506 - accuracy: 0.9972 - val_loss: 0.1109 - val_accuracy: 0.9844\n",
      "Epoch 44/44\n",
      "23/23 [==============================] - 10s 450ms/step - loss: 0.0637 - accuracy: 0.9917 - val_loss: 0.0992 - val_accuracy: 1.0000\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "last_epoch = get_last_epoch(log_file)\n",
    "\n",
    "print(n_epochs, \"epochs composed of\", train_spe, \"batches (steps) of\", BATCH_SIZE, \"images.\")\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "history = model.fit(train_generator, \n",
    "          epochs=last_epoch+n_epochs, \n",
    "          steps_per_epoch=train_spe,\n",
    "          use_multiprocessing=False, \n",
    "          validation_data=val_generator,\n",
    "          validation_steps=val_spe,\n",
    "          callbacks=[tensorboard_callback, csv_logger],\n",
    "          initial_epoch=last_epoch)\n",
    "print(np.max(history.history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to /mnt/nvme-storage/pfauregi/training/thumbails/ADIAC_D38/saved_models/model.json\n",
      "Saved weights to /mnt/nvme-storage/pfauregi/training/thumbails/ADIAC_D38/saved_models/model.h5\n"
     ]
    }
   ],
   "source": [
    "save_model(model, SAVED_MODELS_ROOT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
