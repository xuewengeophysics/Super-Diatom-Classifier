{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import math, random\n",
    "import time, datetime, sys, os, shutil\n",
    "import operator\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "print(tf.config.experimental.list_physical_devices())\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "%run ./variables.ipynb\n",
    "%run ./utils.ipynb\n",
    "%run ../utils/data_utils.ipynb\n",
    "\n",
    "id_map = get_selected_taxons(SELECTED_TAXONS)\n",
    "id_map_inv = get_selected_taxons(SELECTED_TAXONS, inv=True)\n",
    "n_classes = len(list(id_map.keys()))\n",
    "check_dirs(SAVED_MODELS_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing panda arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving dataset from: /mnt/nvme-storage/pfauregi/training/thumbails/ADIAC_D38/dataset/train/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'38/38'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving dataset from: /mnt/nvme-storage/pfauregi/training/thumbails/ADIAC_D38/dataset/test/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'38/38'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test length: 753 - n classes: 38\n",
      "Test length: 84 - n classes: 38\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, _ = get_dataset(TRAIN_DATASET_PATH, ids=False)\n",
    "X_test, y_test, _ = get_dataset(TEST_DATASET_PATH, ids=False)\n",
    "\n",
    "print(\"Test length:\", len(X_train), \"- n classes:\", len(np.unique(y_train)))\n",
    "print(\"Test length:\", len(X_test), \"- n classes:\", len(np.unique(y_test)))\n",
    "\n",
    "# Balance dataset\n",
    "#X_train, y_train, max_samples = balance_dataset(X_train, y_train, max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753 84\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>png_path</th>\n",
       "      <th>taxon_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/nvme-storage/pfauregi/training/thumbails/...</td>\n",
       "      <td>Tabularia_investiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/nvme-storage/pfauregi/training/thumbails/...</td>\n",
       "      <td>Cocconeis_stauroneiformis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/nvme-storage/pfauregi/training/thumbails/...</td>\n",
       "      <td>Opephora_olsenii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/nvme-storage/pfauregi/training/thumbails/...</td>\n",
       "      <td>Tabellaria_quadriseptata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/nvme-storage/pfauregi/training/thumbails/...</td>\n",
       "      <td>Gomphonema_sp.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            png_path  \\\n",
       "0  /mnt/nvme-storage/pfauregi/training/thumbails/...   \n",
       "1  /mnt/nvme-storage/pfauregi/training/thumbails/...   \n",
       "2  /mnt/nvme-storage/pfauregi/training/thumbails/...   \n",
       "3  /mnt/nvme-storage/pfauregi/training/thumbails/...   \n",
       "4  /mnt/nvme-storage/pfauregi/training/thumbails/...   \n",
       "\n",
       "                    taxon_id  \n",
       "0       Tabularia_investiens  \n",
       "1  Cocconeis_stauroneiformis  \n",
       "2           Opephora_olsenii  \n",
       "3   Tabellaria_quadriseptata  \n",
       "4            Gomphonema_sp.1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = {'png_path':  X_train, 'taxon_id': y_train}\n",
    "data_test = {'png_path':  X_test, 'taxon_id': y_test}\n",
    "\n",
    "df_train = pd.DataFrame(data_train, columns = ['png_path', 'taxon_id'])\n",
    "df_test = pd.DataFrame(data_test, columns = ['png_path', 'taxon_id'])\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Prtining some infos\n",
    "print(len(df_train), len(df_test))\n",
    "df_train.head()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                         rotation_range=20, \n",
    "                         brightness_range=[0.8,1.2], \n",
    "                         horizontal_flip=True, \n",
    "                         vertical_flip=True,\n",
    "                         fill_mode='nearest',\n",
    "                         width_shift_range=10,\n",
    "                         height_shift_range=10,\n",
    "                         zoom_range=0.2,\n",
    "                         data_format=\"channels_last\")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                         data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 753 validated image filenames belonging to 38 classes.\n",
      "Found 84 validated image filenames belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "#classes_array = np.unique(y_train)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=df_train,\n",
    "        x_col='png_path',\n",
    "        y_col='taxon_id',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        #classes=classes_array,\n",
    "        class_mode='categorical')\n",
    "val_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=df_test,\n",
    "        x_col='png_path',\n",
    "        y_col='taxon_id',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        classes=train_generator.class_indices,\n",
    "        class_mode='categorical')\n",
    "\n",
    "train_spe = train_generator.samples // BATCH_SIZE\n",
    "val_spe = val_generator.samples // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = train_generator.class_indices\n",
    "f = open(os.path.join(SAVED_MODELS_ROOT, 'model_id_map.csv'), 'w')\n",
    "with f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"taxon\", \"id\"])\n",
    "    for taxon in class_indices:\n",
    "        writer.writerow([taxon, class_indices[taxon]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ni = 0\\nstop = False\\nfor batch in train_generator:\\n    images = batch[0]\\n    labels = batch[1]\\n    for i in range(images.shape[0]):\\n        print(np.argmax(labels[i]))\\n        image = (images[i,:,:,:]*255).astype('uint8')\\n        #print(image)\\n        display(Image.fromarray(image))\\n        i+=1\\n        if i>=1:\\n            stop = True\\n            break\\n    if stop: pass;\\n    #display()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "i = 0\n",
    "stop = False\n",
    "for batch in train_generator:\n",
    "    images = batch[0]\n",
    "    labels = batch[1]\n",
    "    for i in range(images.shape[0]):\n",
    "        print(np.argmax(labels[i]))\n",
    "        image = (images[i,:,:,:]*255).astype('uint8')\n",
    "        #print(image)\n",
    "        display(Image.fromarray(image))\n",
    "        i+=1\n",
    "        if i>=1:\n",
    "            stop = True\n",
    "            break\n",
    "    if stop: pass;\n",
    "    #display()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model desgin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching base model\n",
    "input_tensor = Input(shape=(256, 256, 3))\n",
    "#base_model = InceptionV3(weights='imagenet', input_tensor=input_tensor, include_top=False)\n",
    "base_model = Xception(include_top=False, weights='imagenet', input_tensor=input_tensor, pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model for specifiv case\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "out = Dense(len(train_generator.class_indices.keys()), activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all files in /mnt/nvme-storage/pfauregi/training/thumbails/ADIAC_D38/tensorboard/\n"
     ]
    }
   ],
   "source": [
    "# Setting tensorboard\n",
    "check_dirs(LOG_DIR)\n",
    "delete_all_files_in_folder(LOG_DIR)\n",
    "log_dir = LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file=os.path.join(SAVED_MODELS_ROOT, \"model.log\")\n",
    "#os.remove(log_file)\n",
    "csv_logger = CSVLogger(log_file, append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(lr=0.1, decay=0.0001, momentum=0, nesterov=False)\n",
    "#optimizer = \"nadam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New layers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 epochs composed of 23 batches (steps) of 32 images.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 23 steps, validate for 2 steps\n",
      "Epoch 242/246\n",
      " 1/23 [>.............................] - ETA: 1:23 - loss: 3.7184 - accuracy: 0.0938WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.144393). Check your callbacks.\n",
      "23/23 [==============================] - 13s 559ms/step - loss: 3.4787 - accuracy: 0.1664 - val_loss: 3.4807 - val_accuracy: 0.1875\n",
      "Epoch 243/246\n",
      "23/23 [==============================] - 11s 457ms/step - loss: 2.9480 - accuracy: 0.4341 - val_loss: 3.2257 - val_accuracy: 0.2500\n",
      "Epoch 244/246\n",
      "23/23 [==============================] - 11s 458ms/step - loss: 2.3240 - accuracy: 0.5992 - val_loss: 3.0933 - val_accuracy: 0.2188\n",
      "Epoch 245/246\n",
      "23/23 [==============================] - 10s 451ms/step - loss: 1.8362 - accuracy: 0.6755 - val_loss: 2.9369 - val_accuracy: 0.1875\n",
      "Epoch 246/246\n",
      "23/23 [==============================] - 10s 450ms/step - loss: 1.3957 - accuracy: 0.7642 - val_loss: 2.8349 - val_accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "#n_epochs = 5\n",
    "n_epochs = 5\n",
    "last_epoch = get_last_epoch(log_file)\n",
    "\n",
    "print(n_epochs, \"epochs composed of\", train_spe, \"batches (steps) of\", BATCH_SIZE, \"images.\")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_generator, \n",
    "          epochs=last_epoch+n_epochs, \n",
    "          steps_per_epoch=train_spe,\n",
    "          use_multiprocessing=False, \n",
    "          validation_data=val_generator,\n",
    "          validation_steps=val_spe,\n",
    "          callbacks=[tensorboard_callback, csv_logger],\n",
    "          initial_epoch=last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 epochs composed of 23 batches (steps) of 32 images.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 23 steps, validate for 2 steps\n",
      "Epoch 246/345\n",
      "23/23 [==============================] - 13s 571ms/step - loss: 0.6452 - accuracy: 0.8350 - val_loss: 2.8958 - val_accuracy: 0.2500\n",
      "Epoch 247/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.2454 - accuracy: 0.9334 - val_loss: 1.8269 - val_accuracy: 0.4844\n",
      "Epoch 248/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 0.1185 - accuracy: 0.9723 - val_loss: 1.3694 - val_accuracy: 0.5781\n",
      "Epoch 249/345\n",
      "23/23 [==============================] - 11s 465ms/step - loss: 0.0675 - accuracy: 0.9861 - val_loss: 0.9419 - val_accuracy: 0.7344\n",
      "Epoch 250/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0431 - accuracy: 0.9917 - val_loss: 0.5678 - val_accuracy: 0.8125\n",
      "Epoch 251/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0472 - accuracy: 0.9875 - val_loss: 0.3491 - val_accuracy: 0.8906\n",
      "Epoch 252/345\n",
      "23/23 [==============================] - 11s 472ms/step - loss: 0.0279 - accuracy: 0.9959 - val_loss: 0.2547 - val_accuracy: 0.8906\n",
      "Epoch 253/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 0.2084 - val_accuracy: 0.9219\n",
      "Epoch 254/345\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 0.0169 - accuracy: 0.9972 - val_loss: 0.1260 - val_accuracy: 0.9219\n",
      "Epoch 255/345\n",
      "23/23 [==============================] - 11s 474ms/step - loss: 0.0365 - accuracy: 0.9889 - val_loss: 0.0784 - val_accuracy: 0.9688\n",
      "Epoch 256/345\n",
      "23/23 [==============================] - 11s 465ms/step - loss: 0.0223 - accuracy: 0.9945 - val_loss: 0.1047 - val_accuracy: 0.9844\n",
      "Epoch 257/345\n",
      "23/23 [==============================] - 11s 470ms/step - loss: 0.0420 - accuracy: 0.9875 - val_loss: 0.1792 - val_accuracy: 0.9531\n",
      "Epoch 258/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 0.0141 - accuracy: 0.9986 - val_loss: 0.0594 - val_accuracy: 0.9844\n",
      "Epoch 259/345\n",
      "23/23 [==============================] - 11s 465ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 0.0782 - val_accuracy: 0.9688\n",
      "Epoch 260/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0111 - accuracy: 0.9986 - val_loss: 0.0364 - val_accuracy: 0.9844\n",
      "Epoch 261/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0256 - accuracy: 0.9972 - val_loss: 0.0895 - val_accuracy: 0.9531\n",
      "Epoch 262/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0096 - accuracy: 0.9986 - val_loss: 0.0588 - val_accuracy: 0.9844\n",
      "Epoch 263/345\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 0.0134 - accuracy: 0.9986 - val_loss: 0.3892 - val_accuracy: 0.9219\n",
      "Epoch 264/345\n",
      "23/23 [==============================] - 11s 465ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0545 - val_accuracy: 0.9688\n",
      "Epoch 265/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 0.0266 - accuracy: 0.9972 - val_loss: 0.0681 - val_accuracy: 0.9688\n",
      "Epoch 266/345\n",
      "23/23 [==============================] - 11s 465ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 0.0382 - val_accuracy: 0.9844\n",
      "Epoch 267/345\n",
      "23/23 [==============================] - 11s 464ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 268/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9844\n",
      "Epoch 269/345\n",
      "23/23 [==============================] - 11s 477ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0258 - val_accuracy: 0.9844\n",
      "Epoch 270/345\n",
      "23/23 [==============================] - 11s 465ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9844\n",
      "Epoch 271/345\n",
      "23/23 [==============================] - 11s 473ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9844\n",
      "Epoch 272/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 273/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0228 - accuracy: 0.9958 - val_loss: 0.0429 - val_accuracy: 0.9844\n",
      "Epoch 274/345\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 0.0170 - accuracy: 0.9958 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 275/345\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9844\n",
      "Epoch 276/345\n",
      "23/23 [==============================] - 11s 465ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9844\n",
      "Epoch 277/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9844\n",
      "Epoch 278/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0574 - val_accuracy: 0.9844\n",
      "Epoch 279/345\n",
      "23/23 [==============================] - 11s 465ms/step - loss: 0.0091 - accuracy: 0.9986 - val_loss: 0.0539 - val_accuracy: 0.9844\n",
      "Epoch 280/345\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9844\n",
      "Epoch 281/345\n",
      "23/23 [==============================] - 11s 463ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 282/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9844\n",
      "Epoch 283/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 284/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 285/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 286/345\n",
      "23/23 [==============================] - 11s 465ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 287/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 288/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 0.0038 - accuracy: 0.9972 - val_loss: 0.0441 - val_accuracy: 0.9844\n",
      "Epoch 289/345\n",
      "23/23 [==============================] - 11s 465ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0363 - val_accuracy: 0.9844\n",
      "Epoch 290/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9688\n",
      "Epoch 291/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9844\n",
      "Epoch 292/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9844\n",
      "Epoch 293/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9844\n",
      "Epoch 294/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9844\n",
      "Epoch 295/345\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9844\n",
      "Epoch 296/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9844\n",
      "Epoch 297/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9844\n",
      "Epoch 298/345\n",
      "23/23 [==============================] - 11s 473ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9844\n",
      "Epoch 299/345\n",
      "23/23 [==============================] - 11s 462ms/step - loss: 0.0045 - accuracy: 0.9972 - val_loss: 0.0406 - val_accuracy: 0.9844\n",
      "Epoch 300/345\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9844\n",
      "Epoch 301/345\n",
      "23/23 [==============================] - 11s 470ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9844\n",
      "Epoch 302/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9844\n",
      "Epoch 303/345\n",
      "23/23 [==============================] - 11s 470ms/step - loss: 8.6600e-04 - accuracy: 1.0000 - val_loss: 0.0570 - val_accuracy: 0.9844\n",
      "Epoch 304/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 8.0094e-04 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9844\n",
      "Epoch 305/345\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 9.1622e-04 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9844\n",
      "Epoch 306/345\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 6.7110e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9844\n",
      "Epoch 307/345\n",
      "23/23 [==============================] - 11s 472ms/step - loss: 8.6546e-04 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9844\n",
      "Epoch 308/345\n",
      "23/23 [==============================] - 11s 472ms/step - loss: 8.7907e-04 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9844\n",
      "Epoch 309/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 8.2774e-04 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9844\n",
      "Epoch 310/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 9.8756e-04 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 0.9844\n",
      "Epoch 311/345\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9844\n",
      "Epoch 312/345\n",
      "23/23 [==============================] - 11s 472ms/step - loss: 9.1135e-04 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9844\n",
      "Epoch 313/345\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 8.9731e-04 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9844\n",
      "Epoch 314/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0346 - val_accuracy: 0.9844\n",
      "Epoch 315/345\n",
      "23/23 [==============================] - 11s 472ms/step - loss: 7.6457e-04 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9844\n",
      "Epoch 316/345\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 8.4562e-04 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9844\n",
      "Epoch 317/345\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 6.3131e-04 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 0.9844\n",
      "Epoch 318/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 6.7012e-04 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 0.9844\n",
      "Epoch 319/345\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 7.4845e-04 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9844\n",
      "Epoch 320/345\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 321/345\n",
      "23/23 [==============================] - 11s 468ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0510 - val_accuracy: 0.9844\n",
      "Epoch 322/345\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 8.0066e-04 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9844\n",
      "Epoch 323/345\n",
      "23/23 [==============================] - 11s 464ms/step - loss: 7.4118e-04 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9844\n",
      "Epoch 324/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 8.2978e-04 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9844\n",
      "Epoch 325/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 6.1944e-04 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9844\n",
      "Epoch 326/345\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 8.8588e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9844\n",
      "Epoch 327/345\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 7.0882e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9844\n",
      "Epoch 328/345\n",
      "23/23 [==============================] - 11s 469ms/step - loss: 6.1555e-04 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9844\n",
      "Epoch 329/345\n",
      "23/23 [==============================] - 11s 470ms/step - loss: 6.0351e-04 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9844\n",
      "Epoch 330/345\n",
      "23/23 [==============================] - 11s 470ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 331/345\n",
      "23/23 [==============================] - 11s 464ms/step - loss: 7.2251e-04 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 332/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 5.9855e-04 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 333/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 6.4252e-04 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 334/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 7.6954e-04 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9844\n",
      "Epoch 335/345\n",
      "23/23 [==============================] - 11s 471ms/step - loss: 9.3746e-04 - accuracy: 1.0000 - val_loss: 0.0395 - val_accuracy: 0.9844\n",
      "Epoch 336/345\n",
      "23/23 [==============================] - 11s 470ms/step - loss: 7.1890e-04 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9844\n",
      "Epoch 337/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 6.9767e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9844\n",
      "Epoch 338/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 7.7528e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9844\n",
      "Epoch 339/345\n",
      "23/23 [==============================] - 11s 470ms/step - loss: 4.5193e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9844\n",
      "Epoch 340/345\n",
      "23/23 [==============================] - 11s 474ms/step - loss: 5.1976e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9844\n",
      "Epoch 341/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 6.4441e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9844\n",
      "Epoch 342/345\n",
      "23/23 [==============================] - 11s 467ms/step - loss: 5.0033e-04 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9844\n",
      "Epoch 343/345\n",
      "23/23 [==============================] - 11s 475ms/step - loss: 5.3002e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9844\n",
      "Epoch 344/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 6.2299e-04 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9844\n",
      "Epoch 345/345\n",
      "23/23 [==============================] - 11s 466ms/step - loss: 4.9427e-04 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9844\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#n_epochs = 50\n",
    "n_epochs = 100\n",
    "last_epoch = get_last_epoch(log_file)\n",
    "\n",
    "print(n_epochs, \"epochs composed of\", train_spe, \"batches (steps) of\", BATCH_SIZE, \"images.\")\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "history = model.fit(train_generator, \n",
    "          epochs=last_epoch+n_epochs, \n",
    "          steps_per_epoch=train_spe,\n",
    "          use_multiprocessing=False, \n",
    "          validation_data=val_generator,\n",
    "          validation_steps=val_spe,\n",
    "          callbacks=[tensorboard_callback, csv_logger],\n",
    "          initial_epoch=last_epoch)\n",
    "print(np.max(history.history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, SAVED_MODELS_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
