{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os, shutil\n",
    "from skimage.exposure import match_histograms\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%run ./variables.ipynb\n",
    "%run ./utils.ipynb\n",
    "%run ../utils/data_utils.ipynb\n",
    "%run ../utils/image_utils.ipynb\n",
    "\n",
    "N_LIM = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nvme-storage/pfauregi/datasets/atlas/BRG\n",
      "/mnt/nvme-storage/pfauregi/datasets/atlas/IDF\n",
      "6112 images detected belonging to 162 classes found in 2 atlas!\n",
      "Eliminated taxon (unsufficient number of images): dict_keys(['GYAT', 'GYKU', 'AUAJ', 'PLEV', 'NMIC', 'SPIN', 'GYAC', 'BPAX', 'NVIR'])\n",
      "Train dataset composed of 4889 images and 162 classes.\n",
      "Train dataset composed of 1223 images and 162 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loading reference image for histogram matching and saving ref img\n",
    "ref = cv2.imread(\"/mnt/nvme-storage/pfauregi/datasets/atlas/ref_img.png\", cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imwrite(os.path.join(SAVED_MODELS_ROOT, \"ref_img.png\"), ref)\n",
    "\n",
    "# Fetching files\n",
    "taxons_dict = {}\n",
    "selected_taxons = get_selected_taxons(SELECTED_TAXONS)\n",
    "for path in ATLAS_PATH:\n",
    "    print(path)\n",
    "    for taxon in os.listdir(path):\n",
    "        if taxon in selected_taxons.keys():\n",
    "            dir_path = os.path.join(path, taxon)\n",
    "            files = [f for f in os.listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "            for file in files:\n",
    "                split = file.split(\".\")\n",
    "                if (len(split)>1 and split[1]==\"png\"):\n",
    "                    source_file = os.path.join(dir_path, file)\n",
    "                    target_file = os.path.join(taxon, file)\n",
    "                    img_path = os.path.join(dir_path, file)\n",
    "                    taxons_dict.setdefault(taxon, []).append({\"source\": source_file, \"target\": target_file})\n",
    "\n",
    "# Filtering\n",
    "X, y = [], []\n",
    "eliminated_taxons = {}\n",
    "for taxon in taxons_dict:\n",
    "    files_tmp = taxons_dict[taxon]\n",
    "    if len(files_tmp)>=N_LIM:\n",
    "        X.extend(files_tmp)\n",
    "        y.extend([taxon]*len(files_tmp))\n",
    "    else:\n",
    "        eliminated_taxons.setdefault(taxon, None)\n",
    "        \n",
    "print(len(X) ,\"images detected belonging to\", len(np.unique(y)), \"classes found in\",len(ATLAS_PATH),\"atlas!\")\n",
    "print(\"Eliminated taxon (unsufficient number of images):\", eliminated_taxons.keys())\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "taxons_dict_train = {}\n",
    "taxons_dict_test = {}\n",
    "\n",
    "print(\"Train dataset composed of\", len(X_train), \"images and\", len(np.unique(y_train)), \"classes.\")\n",
    "print(\"Train dataset composed of\", len(X_test), \"images and\", len(np.unique(y_test)), \"classes.\")\n",
    "\n",
    "# Building dataset\n",
    "delete_all_files_in_folder(DATASET_PATH)\n",
    "save_path = [TRAIN_DATASET_PATH, TEST_DATASET_PATH]\n",
    "Xs = [X_train, X_test]\n",
    "Ys = [y_train, y_test]\n",
    "for k in range(len(save_path)):\n",
    "    path = save_path[k]\n",
    "    X = Xs[k]\n",
    "    y = Ys[k]\n",
    "    for i in range(len(X)):\n",
    "        taxon = y[i]\n",
    "        source_file = X[i][\"source\"]\n",
    "        target_file = os.path.join(path, X[i][\"target\"])\n",
    "        check_dirs(target_file)\n",
    "        img = cv2.imread(source_file, cv2.IMREAD_GRAYSCALE)\n",
    "        img = match_histograms(img, ref, multichannel=False).astype(\"uint8\")\n",
    "        img = convert_to_square(img, new_size=256)\n",
    "        cv2.imwrite(target_file, img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
