{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os, shutil\n",
    "from skimage.exposure import match_histograms\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "%run ./variables.ipynb\n",
    "%run ./utils.ipynb\n",
    "%run ../utils/data_utils.ipynb\n",
    "%run ../utils/image_utils.ipynb\n",
    "\n",
    "TEST_SIZE = 0.1\n",
    "norm = False\n",
    "crossval=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter: 80 taxa to select!\n",
      "Processing: /mnt/nvme-storage/pfauregi/datasets/Aqualitas/\n"
     ]
    }
   ],
   "source": [
    "# Get taxa list for filtering\n",
    "if not FILTER_PATH is None:\n",
    "    selected_taxa = get_taxa_list(FILTER_PATH)\n",
    "    print(\"Filter:\", len(selected_taxa), \"taxa to select!\")\n",
    "\n",
    "# Loading reference image for histogram matching and saving ref img\n",
    "ref = cv2.imread(\"/mnt/nvme-storage/pfauregi/datasets/atlas/ref_img.png\", cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imwrite(os.path.join(SAVED_MODELS_ROOT, \"ref_img.png\"), ref)\n",
    "\n",
    "# Fetching files\n",
    "taxa_dict = {}\n",
    "for path in DATASET:\n",
    "    print(\"Processing:\",path)\n",
    "    for taxon in os.listdir(path):\n",
    "        if (FILTER_PATH is None) or (taxon in selected_taxa):\n",
    "            dir_path = os.path.join(path, taxon)\n",
    "            files = [f for f in os.listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "            for file in files:\n",
    "                split = file.split(\".\")\n",
    "                if (len(split)>1 and split[1] in [\"png\", \"tiff\", \"tif\", \"TIF\"]):\n",
    "                    file_root = file.split(\".\")[0]\n",
    "                    source_file = os.path.join(dir_path, file)\n",
    "                    target_file = os.path.join(taxon, file_root+\".png\")\n",
    "                    taxa_dict.setdefault(taxon, []).append({\"source\": source_file, \"target\": target_file})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8668 images detected belonging to 80 classes found in 1 folder!\n",
      "Eliminated taxon (unsufficient number of images): []\n",
      "Deleting all files in /mnt/nvme-storage/pfauregi/training/thumbails/aqualitas/dataset/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'8668/8668'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info saved at: /mnt/nvme-storage/pfauregi/training/thumbails/aqualitas/dataset/dataset_infos.csv\n",
      "108.35 +- 46.95239610499127 images per taxon!\n",
      "Finished !\n"
     ]
    }
   ],
   "source": [
    "# Filtering\n",
    "X, y = [], []\n",
    "eliminated_taxa = {}\n",
    "for taxon in taxa_dict:\n",
    "    files_tmp = taxa_dict[taxon]\n",
    "    if len(files_tmp)>=RANGE[0]:\n",
    "        if len(files_tmp)>=RANGE[1]: files_tmp = np.random.permutation(files_tmp)[0:RANGE[1]]\n",
    "        X.extend(files_tmp)\n",
    "        y.extend([taxon]*len(files_tmp))\n",
    "    else:\n",
    "        eliminated_taxa.setdefault(taxon, None)\n",
    "eliminated_taxa = list(eliminated_taxa.keys())\n",
    "print(len(X) ,\"images detected belonging to\", len(np.unique(y)), \"classes found in\",len(DATASET),\"folder!\")\n",
    "print(\"Eliminated taxon (unsufficient number of images):\", eliminated_taxa)\n",
    "\n",
    "# Building dataset\n",
    "check_dirs(DATASET_PATH)\n",
    "delete_all_files_in_folder(DATASET_PATH)\n",
    "a = display(str(0)+\"/\"+str(len(X)),display_id=True)\n",
    "for i in range(len(X)):\n",
    "    a.update(str(i+1)+\"/\"+str(len(X)))\n",
    "    taxon = y[i]\n",
    "    source_file = X[i][\"source\"]\n",
    "    target_file = os.path.join(DATASET_PATH, X[i][\"target\"])\n",
    "    check_dirs(target_file)\n",
    "    img = cv2.imread(source_file, cv2.IMREAD_GRAYSCALE)\n",
    "    if norm: img = match_histograms(img, ref, multichannel=False).astype(\"uint8\")\n",
    "    img = convert_to_square(img, new_size=256)\n",
    "    cv2.imwrite(target_file, img)\n",
    "        \n",
    "# Save dataset infos\n",
    "csv_path = os.path.join(DATASET_PATH, 'dataset_infos.csv')\n",
    "f = open(csv_path, 'w')\n",
    "n_taxa = []\n",
    "with f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"taxon\", \"n_images\"])\n",
    "    for taxon in taxa_dict:\n",
    "        if not taxon in eliminated_taxa:\n",
    "            writer.writerow([taxon, len(taxa_dict[taxon])])\n",
    "            n_taxa.append(len(taxa_dict[taxon]))\n",
    "print(\"Dataset info saved at:\",csv_path)\n",
    "print(np.mean(n_taxa),\"+-\",np.std(n_taxa),\"images per taxon!\")\n",
    "print(\"Finished !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
