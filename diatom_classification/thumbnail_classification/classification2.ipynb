{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from os import listdir, walk\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import cv2\n",
    "from sys import getsizeof\n",
    "from IPython.display import display\n",
    "import random\n",
    "import math\n",
    "import datetime\n",
    "import sys\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#tf.config.optimizer.set_jit(True)\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "print(tf.config.experimental.list_physical_devices())\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "STEPS_PER_EPOCH = 600\n",
    "VALIDATION_STEPS = 30\n",
    "\n",
    "\n",
    "%run ./variables.ipynb\n",
    "%run ./utils.ipynb\n",
    "%run ../utils/data_utils.ipynb\n",
    "\n",
    "id_map = get_selected_taxons(\"../../selected_taxons.txt\")\n",
    "id_map_inv = get_selected_taxons(\"../../selected_taxons.txt\", inv=True)\n",
    "n_classes = len(list(id_map.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = max(id_map.items(), key=operator.itemgetter(1))[1]\n",
    "classes_array = [None]*(size+1)\n",
    "for el in id_map:\n",
    "    classes_array[id_map[el]]=el\n",
    "classes_array[0]=\"DUST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4990 images belonging to 230 classes.\n",
      "Found 1154 images belonging to 230 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255.,\n",
    "                         rotation_range=90, \n",
    "                         brightness_range=[0.8,1.2], \n",
    "                         horizontal_flip=True, \n",
    "                         vertical_flip=True,\n",
    "                         fill_mode='nearest',\n",
    "                         width_shift_range=40,\n",
    "                         height_shift_range=40,\n",
    "                         zoom_range=0.2,\n",
    "                         zca_whitening=True,\n",
    "                         validation_split=0.2) \n",
    "train_generator = datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    classes=classes_array,\n",
    "    batch_size=32,\n",
    "    subset=\"training\",\n",
    "    seed=27)\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    classes=classes_array,\n",
    "    batch_size=32,\n",
    "    subset=\"validation\",\n",
    "    seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in train_generator:\n",
    "    i+=1\n",
    "    images = batch[0]\n",
    "    labels = batch[1]\n",
    "    for i in range(images.shape[0]):\n",
    "        print(np.argmax(labels[i]))\n",
    "        image = (images[i,:,:,:]*255).astype('uint8')\n",
    "        #print(image)\n",
    "        display(Image.fromarray(image))\n",
    "    #display()\n",
    "    if i>=1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model desgin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching base model\n",
    "#base_model = Xception(include_top=False, weights='imagenet', input_shape=(256, 256, 3), pooling=None)\n",
    "input_tensor = Input(shape=(256, 256, 3))\n",
    "base_model = InceptionV3(weights='imagenet', input_tensor=input_tensor, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting model for specifiv case\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "out = Dense(230, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting tensorboard\n",
    "!rm -rf LOG_DIR\n",
    "log_dir = LOG_DIR + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New layers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 epochs composed of 923 batches (steps) of 32 images.\n"
     ]
    }
   ],
   "source": [
    "print(int(0.1*N_EPOCHS), \"epochs composed of\", (int(train_size/BATCH_SIZE)-1), \"batches (steps) of\", BATCH_SIZE, \"images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 924 steps, validate for 231 steps\n",
      "Epoch 1/3\n",
      "  1/924 [..............................] - ETA: 1:32:57 - loss: 5.4720 - accuracy: 0.0312WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.193511). Check your callbacks.\n",
      "924/924 [==============================] - 76s 83ms/step - loss: 2.8451 - accuracy: 0.3487 - val_loss: 4.2532 - val_accuracy: 0.1201\n",
      "Epoch 2/3\n",
      "924/924 [==============================] - 75s 81ms/step - loss: 1.4774 - accuracy: 0.5947 - val_loss: 4.8679 - val_accuracy: 0.1305\n",
      "Epoch 3/3\n",
      "924/924 [==============================] - 73s 79ms/step - loss: 1.1828 - accuracy: 0.6652 - val_loss: 5.4622 - val_accuracy: 0.1272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0654615f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs_train1 = 3\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "model.fit(train_generator, \n",
    "          epochs=n_epochs_train1, \n",
    "          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          use_multiprocessing=True, \n",
    "          validation_data=val_generator,\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          callbacks=[tensorboard_callback],\n",
    "          initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_train1 = train_dataset.repeat(n_epochs_train1).batch(BATCH_SIZE)\n",
    "val_train1 = val_dataset.repeat(n_epochs_train1).batch(BATCH_SIZE)\n",
    "\n",
    "print(n_epochs_train1*int(train_size/BATCH_SIZE))\n",
    "print(tf.data.experimental.cardinality(train_train1).numpy())\n",
    "print(n_epochs_train1*int(val_size/BATCH_SIZE))\n",
    "print(int(tf.data.experimental.cardinality(val_train1).numpy()))\n",
    "val_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 2 last inceptions blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs_train2 = n_epochs_train1+10\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit(train_generator, \n",
    "          epochs=n_epochs_train2, \n",
    "          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          use_multiprocessing=True, \n",
    "          validation_data=val_generator,\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          callbacks=[tensorboard_callback],\n",
    "          initial_epoch=n_epochs_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 923 steps, validate for 230 steps\n",
      "Epoch 14/33\n",
      "923/923 [==============================] - 155s 168ms/step - loss: 0.7994 - accuracy: 0.7686 - val_loss: 0.5006 - val_accuracy: 0.8414\n",
      "Epoch 15/33\n",
      "923/923 [==============================] - 148s 161ms/step - loss: 0.3591 - accuracy: 0.8835 - val_loss: 0.6138 - val_accuracy: 0.8069\n",
      "Epoch 16/33\n",
      "923/923 [==============================] - 149s 161ms/step - loss: 0.2694 - accuracy: 0.9124 - val_loss: 0.2737 - val_accuracy: 0.9087\n",
      "Epoch 17/33\n",
      "923/923 [==============================] - 149s 162ms/step - loss: 0.2250 - accuracy: 0.9268 - val_loss: 1.2448 - val_accuracy: 0.7073\n",
      "Epoch 18/33\n",
      "923/923 [==============================] - 149s 162ms/step - loss: 0.1946 - accuracy: 0.9356 - val_loss: 0.3018 - val_accuracy: 0.9049\n",
      "Epoch 19/33\n",
      "923/923 [==============================] - 149s 162ms/step - loss: 0.1636 - accuracy: 0.9486 - val_loss: 0.3730 - val_accuracy: 0.8852\n",
      "Epoch 20/33\n",
      "923/923 [==============================] - 149s 162ms/step - loss: 0.1622 - accuracy: 0.9468 - val_loss: 0.2106 - val_accuracy: 0.9340\n",
      "Epoch 21/33\n",
      "923/923 [==============================] - 149s 162ms/step - loss: 0.1395 - accuracy: 0.9551 - val_loss: 0.2097 - val_accuracy: 0.9311\n",
      "Epoch 22/33\n",
      "923/923 [==============================] - 149s 162ms/step - loss: 0.1198 - accuracy: 0.9607 - val_loss: 0.3037 - val_accuracy: 0.9167\n",
      "Epoch 23/33\n",
      "923/923 [==============================] - 149s 162ms/step - loss: 0.1073 - accuracy: 0.9663 - val_loss: 0.6767 - val_accuracy: 0.8292\n",
      "Epoch 24/33\n",
      "923/923 [==============================] - 149s 162ms/step - loss: 0.1087 - accuracy: 0.9656 - val_loss: 0.1565 - val_accuracy: 0.9477\n",
      "Epoch 25/33\n",
      "923/923 [==============================] - 150s 162ms/step - loss: 0.0987 - accuracy: 0.9695 - val_loss: 0.2322 - val_accuracy: 0.9344\n",
      "Epoch 26/33\n",
      "923/923 [==============================] - 149s 162ms/step - loss: 0.0877 - accuracy: 0.9714 - val_loss: 0.3257 - val_accuracy: 0.9179\n",
      "Epoch 27/33\n",
      "923/923 [==============================] - 149s 162ms/step - loss: 0.0762 - accuracy: 0.9755 - val_loss: 0.0899 - val_accuracy: 0.9719\n",
      "Epoch 28/33\n",
      "923/923 [==============================] - 149s 162ms/step - loss: 0.0802 - accuracy: 0.9750 - val_loss: 0.1610 - val_accuracy: 0.9503\n",
      "Epoch 29/33\n",
      "923/923 [==============================] - 149s 161ms/step - loss: 0.0708 - accuracy: 0.9779 - val_loss: 0.1382 - val_accuracy: 0.9577\n",
      "Epoch 30/33\n",
      "923/923 [==============================] - 149s 161ms/step - loss: 0.0683 - accuracy: 0.9786 - val_loss: 0.1013 - val_accuracy: 0.9694\n",
      "Epoch 31/33\n",
      "923/923 [==============================] - 149s 161ms/step - loss: 0.0652 - accuracy: 0.9797 - val_loss: 0.1134 - val_accuracy: 0.9606\n",
      "Epoch 32/33\n",
      "923/923 [==============================] - 149s 161ms/step - loss: 0.0582 - accuracy: 0.9824 - val_loss: 0.1118 - val_accuracy: 0.9679\n",
      "Epoch 33/33\n",
      "923/923 [==============================] - 149s 161ms/step - loss: 0.0597 - accuracy: 0.9808 - val_loss: 0.0468 - val_accuracy: 0.9846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe064f75550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs_train3 = n_epochs_train2+20\n",
    "\n",
    "train_train3 = train_dataset.repeat(n_epochs_train3).batch(BATCH_SIZE)\n",
    "val_train3 = val_dataset.repeat(n_epochs_train3).batch(BATCH_SIZE)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit(train_generator, \n",
    "          epochs=n_epochs_train3, \n",
    "          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          use_multiprocessing=True, \n",
    "          validation_data=val_generator,\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          callbacks=[tensorboard_callback],\n",
    "          initial_epoch=n_epochs_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.save_weights(\"./saved_models/model.h5\")\n",
    "model_json = model.to_json()\n",
    "with open(\"./saved_models/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "    # serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_dataset, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [np.argmax(pred) for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(0.1*N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
