{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "\n",
    "%run ../utils/object_detection_utils.ipynb\n",
    "%run ../utils/image_utils.ipynb\n",
    "%run ../utils/data_utils.ipynb\n",
    "%run ./variables.ipynb\n",
    "%run ./utils.ipynb\n",
    "\n",
    "id_map_path = os.path.join(SAVED_MODELS_ROOT, 'model_id_map.csv')\n",
    "id_map = get_selected_taxons(id_map_path)\n",
    "inv_id_map = get_selected_taxons(id_map_path, inv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting ytest and ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = [], []\n",
    "images_paths=read_csv(os.path.join(SAVED_MODELS_ROOT, \"test_list.csv\"))\n",
    "for image_path in images_paths:\n",
    "    X_test.append(image_path)\n",
    "    y_test.append(id_map[image_path.split(\"/\")[-2]])\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/mnt/nvme-storage/pfauregi/training/thumbails/atlas/saved_models/model.json' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "json_file = open(os.path.join(SAVED_MODELS_ROOT, \"model.json\"), 'r')\n",
    "print(json_file)\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(os.path.join(SAVED_MODELS_ROOT, \"weights.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbails_batch = []\n",
    "for file in X_test:\n",
    "    sample = load_image(file, expand=True)\n",
    "    thumbails_batch.append(sample)\n",
    "    #display(Image.fromarray(sample))\n",
    "thumbails_batch = np.array(thumbails_batch).astype('float32')/255\n",
    "outs = model.predict(thumbails_batch, use_multiprocessing=True)\n",
    "y_pred = np.array([np.argmax(out) for out in outs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_test, open( \"ytest.p\", \"wb\" ))\n",
    "pickle.dump(y_pred, open( \"ypred.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating artifical taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pickle.load( open( \"ytest.p\", \"rb\" ) )\n",
    "y_pred = pickle.load( open( \"ypred.p\", \"rb\" ) )\n",
    "tmp=np.abs(y_test-y_pred)\n",
    "print(\"Accuracy:\", len(np.where(tmp==0)[0])/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = tf.math.confusion_matrix(y_test, y_pred).numpy()\n",
    "C_norm = C/C.astype(np.float).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8565656565656565"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_perc = conf_mat.copy().astype(\"float32\")\n",
    "for i in range(len(conf_mat_perc)):\n",
    "    conf_mat_perc[i] = conf_mat_perc[i]/np.sum(conf_mat_perc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(id_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.set()\n",
    "df_cm = pd.DataFrame(conf_mat_perc, index = [i for i in labels],\n",
    "                  columns = [i for i in labels])\n",
    "fig = plt.figure(figsize = (100,70))\n",
    "sn.heatmap(df_cm,\n",
    "           annot=True)\n",
    "           #norm=LogNorm())\n",
    "           #cbar_kws={'format': FuncFormatter(fmt)})\n",
    "fig.savefig('foo.png', bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
