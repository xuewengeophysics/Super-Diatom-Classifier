{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "import PIL.Image\n",
    "import multiprocessing\n",
    "from lxml import etree\n",
    "\n",
    "%run ./generator.ipynb\n",
    "%run ./variables.ipynb\n",
    "%run ./utils.ipynb\n",
    "\n",
    "TEST = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_maps():\n",
    "    images = []\n",
    "    for path in DATASET_PATH:\n",
    "        images.extend([f for f in listdir(path) if isfile(join(path, f))])\n",
    "\n",
    "    tmp_code = {}\n",
    "    i = 1\n",
    "    for file in images:\n",
    "        taxon = file.split('_')[1]\n",
    "        if not (taxon in tmp_code):\n",
    "            tmp_code[taxon] = i\n",
    "            i+=1\n",
    "\n",
    "    savePickle(tmp_code, SAVE_PATH+\"/maps/multiclass_label_map.pickle\")\n",
    "    binary_tmp_code = {}\n",
    "    binary_tmp_code[\"diatom\"] = 1\n",
    "    savePickle(binary_tmp_code, SAVE_PATH+\"/maps/binary_label_map.pickle\")\n",
    "    print(\"Binary and multiclass label maps saved successfully !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(lock, n_id, wnumber, verbose):\n",
    "    print(\"Worker \", wnumber, \" ok!\")\n",
    "    random.seed()\n",
    "    lock.acquire()\n",
    "    wid = n_id.value\n",
    "    if verbose:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Worker \", wnumber, \": \", (wid+1),\"/\", N_IMAGES)\n",
    "    n_id.value += 1\n",
    "    lock.release()\n",
    "    while(wid<=N_IMAGES):\n",
    "        final_img, annotations = main_generator(simple_angles = False, \n",
    "                                          size_px = 1000,\n",
    "                                          verbose=False, \n",
    "                                          overlapping=0.3, \n",
    "                                          n_diatoms=[9,12],\n",
    "                                          scale_diatoms=[7,5],                                          \n",
    "                                          n_dust=[25,40],\n",
    "                                          scale_dust=[3,4])\n",
    "        string_id = '{:05d}'.format(wid)\n",
    "        final_img = final_img[:,:,1]\n",
    "        \n",
    "        # Init xml tree\n",
    "        xml_root = etree.Element(\"annotation\")\n",
    "        etree.SubElement(xml_root, \"folder\").text = \"images\"\n",
    "        etree.SubElement(xml_root, \"filename\").text = string_id+\".png\"\n",
    "        source_xml = etree.SubElement(xml_root, \"source\")\n",
    "        etree.SubElement(source_xml, \"database\").text = DATASET_NAME\n",
    "        size_xml = etree.SubElement(xml_root, \"size\")\n",
    "        etree.SubElement(size_xml, \"width\").text = str(final_img.shape[0])\n",
    "        etree.SubElement(size_xml, \"height\").text = str(final_img.shape[1])\n",
    "        etree.SubElement(size_xml, \"depth\").text = str(1)\n",
    "        \n",
    "        path_img = \"images/\"+string_id+\".png\"\n",
    "        saveImg(final_img, join(SAVE_PATH, path_img));\n",
    "\n",
    "        ## Saving individual masks\n",
    "        taxon_n = {}\n",
    "        paths = []\n",
    "        for annotation in annotations:\n",
    "            taxon = annotation[\"taxon\"]\n",
    "            if taxon in taxon_n:\n",
    "                taxon_n[taxon] += 1\n",
    "            else:\n",
    "                taxon_n[taxon] = 0\n",
    "            path_mask = \"masks/\"+string_id+\"_\"+taxon+\"_\"+'{:03d}'.format(taxon_n[taxon])+\".png\"\n",
    "            # Saving mask\n",
    "            img = PIL.Image.fromarray(annotation[\"patch_mask\"])\n",
    "            annotation.pop(\"patch_mask\")\n",
    "            #output = io.BytesIO()\n",
    "            check_dirs(join(SAVE_PATH, path_mask))\n",
    "            #img.save(join(SAVE_PATH, path_mask), format='PNG')\n",
    "            annotation[\"mask_path\"] = path_mask\n",
    "            # Adding bounding box to xml\n",
    "            object_xml = etree.SubElement(xml_root, \"object\")\n",
    "            etree.SubElement(object_xml, \"name\").text = annotation[\"taxon\"]\n",
    "            etree.SubElement(object_xml, \"xmin\").text = str(annotation[\"xmin\"])\n",
    "            etree.SubElement(object_xml, \"ymin\").text = str(annotation[\"ymin\"])\n",
    "            etree.SubElement(object_xml, \"xmax\").text = str(annotation[\"xmax\"])\n",
    "            etree.SubElement(object_xml, \"ymax\").text = str(annotation[\"ymax\"])        \n",
    "        \n",
    "        # Saving annotation\n",
    "        et = etree.ElementTree(xml_root)\n",
    "        xml_path = os.path.join(SAVE_PATH, \"annotations/\", string_id+\".xml\")\n",
    "        check_dirs(xml_path)\n",
    "        with open(xml_path, 'wb') as xml_file:\n",
    "            et.write(xml_file, pretty_print=True)\n",
    "        \n",
    "        # Incrementing id\n",
    "        lock.acquire()\n",
    "        wid = n_id.value\n",
    "        if verbose:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Worker \", wnumber, \": \", (wid+1), \"/\", N_IMAGES)\n",
    "        n_id.value += 1\n",
    "        lock.release()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker  7 :  16670 / 20000\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "jobs = []\n",
    "n_process = 8\n",
    "n_id = multiprocessing.Value('i', 0)\n",
    "lock = multiprocessing.Lock()\n",
    "verbose = True\n",
    "save_maps()\n",
    "print(\"Generating\", N_IMAGES, \"images with \", n_process, \" workers !\")\n",
    "for i in range(n_process):\n",
    "    p = multiprocessing.Process(target=worker, args=(lock, n_id, i, verbose,))\n",
    "    jobs.append(p)\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
