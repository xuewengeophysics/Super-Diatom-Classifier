{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBdjK2G5ywuc"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os, io\n",
    "import six.moves.urllib as urllib\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import pathlib\n",
    "\n",
    "# Personnal imports\n",
    "%run ../utils/object_detection_utils.ipynb\n",
    "%run ../utils/data_utils.ipynb\n",
    "%run ../global_variables.ipynb\n",
    "%run ./detect_variables.ipynb\n",
    "\n",
    "# Object detection API\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "utils_ops.tf = tf.compat.v1\n",
    "tf.gfile = tf.io.gfile\n",
    "\n",
    "MODEL_ROOT = os.path.join(OD_ROOT, \"ws_fine_tuning/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF-YlMl8c_bM"
   },
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = tf.saved_model.load(os.path.join(MODEL_ROOT,\"export/saved_model/\"))\n",
    "model = model.signatures['serving_default']\n",
    "# Category index\n",
    "PATH_TO_LABELS = os.path.join(MODEL_ROOT,\"dataset/binary_label_map.pbtxt\")\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Computing stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbs(source, bbs, bbs_scores=None, min_score=0, colors=None, text_scale=2):\n",
    "    img = source.copy()\n",
    "    for i, bb in enumerate(bbs):\n",
    "        color = colors[i]\n",
    "        if bbs_scores is None or bbs_scores[i]>min_score:\n",
    "            ymin, xmin, ymax, xmax = bb\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color, 4)\n",
    "            if not bbs_scores is None:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(img,  \"{:.2f}\".format(bbs_scores[i]), (xmin+5, ymin+int(text_scale*30)), font, text_scale*1, color, 3, cv2.LINE_AA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_path=\"/mnt/nvme-storage/pfauregi/training/obj_detection/eval/real_dataset/test_list.csv\"\n",
    "annotations_paths=[]\n",
    "with open(list_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    for row in reader:\n",
    "        annotations_paths.append(''.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting groundtruth and predicted bounding boxes of 55 images(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1/55'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nvme-storage/pfauregi/datasets/real_dataset/./annotations/RUISSEAU-FORGES_02-SampleName2-75-8.xml\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/conv1/Conv2D (defined at <ipython-input-22-8b8f897f951c>:2) ]]\n\t [[SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Select_2/_328]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/conv1/Conv2D (defined at <ipython-input-22-8b8f897f951c>:2) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_pruned_8149]\n\nFunction call stack:\npruned -> pruned\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6a49c1c84d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Fetching predicted bounding boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mprediction_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference_for_single_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mpredicted_bbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mpredicted_bbs_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-7677e647f8c4>\u001b[0m in \u001b[0;36mrun_inference_for_single_image\u001b[0;34m(model, image)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Run inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# All outputs are batches tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/pfauregi/venv/tf2.1/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/pfauregi/venv/tf2.1/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/pfauregi/venv/tf2.1/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/pfauregi/venv/tf2.1/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/mnt/nvme-storage/pfauregi/venv/tf2.1/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/conv1/Conv2D (defined at <ipython-input-22-8b8f897f951c>:2) ]]\n\t [[SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Select_2/_328]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/conv1/Conv2D (defined at <ipython-input-22-8b8f897f951c>:2) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_pruned_8149]\n\nFunction call stack:\npruned -> pruned\n"
     ]
    }
   ],
   "source": [
    "#annotation_root=os.path.join(DATASET_ROOT, VAL_FOLDER, ANNOTATION_FOLDER)\n",
    "#annotations_paths = return_all_files_in_folder_rec(annotation_root, [\"xml\"])\n",
    "comp_images=True\n",
    "\n",
    "print(\"Extracting groundtruth and predicted bounding boxes of \"+str(len(annotations_paths))+\" images(s).\")\n",
    "a = display(str(0)+\"/\"+str(len(annotations_paths)),display_id=True)\n",
    "all_groundtruth_bbs = []\n",
    "all_predicted_bbs = []\n",
    "all_predicted_bbs_scores = []\n",
    "for i, annotation_path in enumerate(annotations_paths):\n",
    "    print(annotation_path)\n",
    "    a.update(str(i+1)+\"/\"+str(len(annotations_paths)))\n",
    "    annotation = parse_annotation(annotation_path)\n",
    "    filename = annotation[\"filename\"].split(\".\")[0]\n",
    "    if IMAGE_FOLDER is None:\n",
    "        print()\n",
    "        image_path = os.path.join(DATASET_ROOT, VAL_FOLDER, annotation[\"folder\"], annotation[\"filename\"])\n",
    "    else:\n",
    "        image_path = os.path.join(DATASET_ROOT, VAL_FOLDER, IMAGE_FOLDER, annotation[\"filename\"])\n",
    "    image = load_image(image_path, expand=True)\n",
    "    height, width, channels = image.shape\n",
    "    # Fetching groundtruth bounding boxes\n",
    "    groundtruth_bbs = []\n",
    "    groundtruth_bbs_colors = []\n",
    "    color_dict = {\"diatom\":(255, 0, 0), \"diatom_floue\":(0, 255, 0), \"diatom_debri\":(0, 0, 255)}\n",
    "    for obj_bb in annotation[\"objects\"]:\n",
    "        if obj_bb[\"name\"] in [\"diatom\", \"diatom_floue\",\"diatom_debri\"]:\n",
    "        #if obj_bb[\"name\"] in [\"diatom\"]:\n",
    "            groundtruth_bbs.append([obj_bb[\"ymin\"], obj_bb[\"xmin\"], obj_bb[\"ymax\"], obj_bb[\"xmax\"]])\n",
    "            groundtruth_bbs_colors.append(color_dict[obj_bb[\"name\"]])\n",
    "\n",
    "    # Fetching predicted bounding boxes\n",
    "    prediction_result = run_inference_for_single_image(model, image)\n",
    "    predicted_bbs = []\n",
    "    predicted_bbs_scores = []\n",
    "    predicted_bbs_colors = []\n",
    "    for box, score in zip(prediction_result['detection_boxes'], prediction_result['detection_scores']):\n",
    "        ymin, xmin, ymax, xmax = int(box[0]*height), int(box[1]*width), int(box[2]*height), int(box[3]*width)\n",
    "        predicted_bbs.append([ymin, xmin, ymax, xmax])\n",
    "        predicted_bbs_scores.append(score)\n",
    "        predicted_bbs_colors.append((255, 0, 0))\n",
    "    \n",
    "    all_groundtruth_bbs.extend(groundtruth_bbs)\n",
    "    all_predicted_bbs.extend(predicted_bbs)\n",
    "    all_predicted_bbs_scores.extend(predicted_bbs_scores)\n",
    "    \n",
    "    # Exporting comparison images\n",
    "    if comp_images:\n",
    "        image_prediction = draw_bbs(image, predicted_bbs, colors=predicted_bbs_colors, bbs_scores=predicted_bbs_scores, min_score=0.9, text_scale=1)\n",
    "        image_groundtruth = draw_bbs(image, groundtruth_bbs, colors=groundtruth_bbs_colors, text_scale=1)\n",
    "        # Creating and saving comparison image\n",
    "        comp_image = np.hstack((image_prediction, image_groundtruth))\n",
    "        comp_image_path = os.path.join(OUTPUT_TMP, \"images/\", filename+\"_comp.png\")\n",
    "        save_img(cv2.resize(comp_image, (0,0), fx=0.5, fy=0.5), comp_image_path, compress=5)\n",
    "        #save_img(image_groundtruth, comp_image_path)\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOC Pascal Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libPath = \"/home/pfauregi/lib/Object-Detection-Metrics/lib\"\n",
    "add_path(libPath)\n",
    "from BoundingBox import BoundingBox\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "from Evaluator import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "boundingboxes = BoundingBoxes()\n",
    "for box in all_groundtruth_bbs:\n",
    "    bb = BoundingBox(\n",
    "        filename,\n",
    "        \"diatom\",\n",
    "        box[1],\n",
    "        box[0],\n",
    "        box[3],\n",
    "        box[2],\n",
    "        CoordinatesType.Absolute,\n",
    "        bbType=BBType.GroundTruth,\n",
    "        format=BBFormat.XYX2Y2)\n",
    "    boundingboxes.addBoundingBox(bb)\n",
    "for i,box in enumerate(all_predicted_bbs):\n",
    "    bb = BoundingBox(\n",
    "                filename,\n",
    "                \"diatom\",\n",
    "                box[1],\n",
    "                box[0],\n",
    "                box[3],\n",
    "                box[2],\n",
    "                CoordinatesType.Absolute,\n",
    "                bbType=BBType.Detected,\n",
    "                classConfidence=all_predicted_bbs_scores[i],\n",
    "                format=BBFormat.XYX2Y2)\n",
    "    boundingboxes.addBoundingBox(bb)\n",
    "print(\"Finished formatting the bounding boxes!\")\n",
    "    \n",
    "# Uncomment the line below to generate images based on the bounding boxes\n",
    "\n",
    "# Create an evaluator object in order to obtain the metrics\n",
    "evaluator = Evaluator()\n",
    "# Plot Precision x Recall curve\n",
    "evaluator.PlotPrecisionRecallCurve(\n",
    "    boundingboxes,  # Object containing all bounding boxes (ground truths and detections)\n",
    "    IOUThreshold=0.3,  # IOU threshold\n",
    "    method=MethodAveragePrecision.EveryPointInterpolation,  # As the official matlab code\n",
    "    showAP=True,  # Show Average Precision in the title of the plot\n",
    "    savePath=\".\",\n",
    "    showInterpolatedPrecision=True)  # Plot the interpolated precision curve\n",
    "# Get metrics with PASCAL VOC metrics\n",
    "metricsPerClass = evaluator.GetPascalVOCMetrics(\n",
    "    boundingboxes,  # Object containing all bounding boxes (ground truths and detections)\n",
    "    IOUThreshold=0.3,  # IOU threshold\n",
    "    method=MethodAveragePrecision.EveryPointInterpolation)  # As the official matlab code\n",
    "print(\"Average precision values per class:\\n\")\n",
    "# Loop through classes to obtain their metrics\n",
    "#print(metricsPerClass)\n",
    "for mc in metricsPerClass:\n",
    "    # Get metric values per each class\n",
    "    c = mc['class']\n",
    "    precision = mc['precision']\n",
    "    recall = mc['recall']\n",
    "    average_precision = mc['AP']\n",
    "    ipre = mc['interpolated precision']\n",
    "    irec = mc['interpolated recall']\n",
    "    # Print AP per class\n",
    "    print('%s: %f' % (c, average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/brain/python/client:colab_notebook",
    "kind": "private"
   },
   "name": "object_detection_tutorial.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1LNYL6Zsn9Xlil2CVNOTsgDZQSBKeOjCh",
     "timestamp": 1566498233247
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1566488313397
    },
    {
     "file_id": "/piper/depot/google3/third_party/py/tensorflow_docs/g3doc/en/r2/tutorials/generative/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1566145894046
    },
    {
     "file_id": "1nBPoWynOV0auSIy40eQcBIk9C6YRSkI8",
     "timestamp": 1566145841085
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1556295408037
    },
    {
     "file_id": "1layerger-51XwWOwYMY_5zHaCavCeQkO",
     "timestamp": 1556214267924
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1556207836484
    },
    {
     "file_id": "1w6mqQiNV3liPIX70NOgitOlDF1_4sRMw",
     "timestamp": 1556154824101
    },
    {
     "file_id": "https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb",
     "timestamp": 1556150293326
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
