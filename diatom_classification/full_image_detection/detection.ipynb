{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBdjK2G5ywuc"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os, io\n",
    "import six.moves.urllib as urllib\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import pathlib\n",
    "\n",
    "# Personnal imports\n",
    "%run ../utils/object_detection_utils.ipynb\n",
    "%run ../utils/data_utils.ipynb\n",
    "%run ../global_variables.ipynb\n",
    "%run ./detect_variables.ipynb\n",
    "\n",
    "# Object detection API\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "utils_ops.tf = tf.compat.v1\n",
    "tf.gfile = tf.io.gfile\n",
    "\n",
    "MODEL_ROOT = os.path.join(OD_ROOT, \"ws_bd2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF-YlMl8c_bM"
   },
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = tf.saved_model.load(os.path.join(MODEL_ROOT,\"export/saved_model/\"))\n",
    "model = model.signatures['serving_default']\n",
    "# Category index\n",
    "PATH_TO_LABELS = os.path.join(MODEL_ROOT,\"dataset/binary_label_map.pbtxt\")\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Computing stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbs(source, bbs, bbs_scores=None, min_score=0, colors=None, text_scale=2):\n",
    "    img = source.copy()\n",
    "    for i, bb in enumerate(bbs):\n",
    "        color = colors[i]\n",
    "        if bbs_scores is None or bbs_scores[i]>min_score:\n",
    "            ymin, xmin, ymax, xmax = bb\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color, 4)\n",
    "            if not bbs_scores is None:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(img,  \"{:.2f}\".format(bbs_scores[i]), (xmin+5, ymin+int(text_scale*30)), font, text_scale*1, color, 3, cv2.LINE_AA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting groundtruth and predicted bounding boxes of 3001 images(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'24/3001'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/01827_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/02272_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/02474_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/00666_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/02647_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/00950_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/02629_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/02663_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/00352_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/02339_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/00696_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/02588_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/00059_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/01200_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/00814_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/00954_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/01234_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/00933_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/02790_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/01581_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/00792_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/02139_comp.png saved sucessfully!\n",
      "Image /mnt/nvme-storage/pfauregi/rw/tmp/images/00489_comp.png saved sucessfully!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-59ed8446548d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Fetching predicted bounding boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mprediction_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference_for_single_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mpredicted_bbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpredicted_bbs_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-7677e647f8c4>\u001b[0m in \u001b[0;36mrun_inference_for_single_image\u001b[0;34m(model, image)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Convert to numpy arrays, and take index [0] to remove the batch dimension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# We're only interested in the first num_detections.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mnum_detections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_detections'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     output_dict = {key:value[0, :num_detections].numpy() \n\u001b[1;32m     16\u001b[0m                  for key,value in output_dict.items()}\n",
      "\u001b[0;32m/mnt/nvme-storage/pfauregi/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__int__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m   \u001b[0;31m# only work for scalars; values are cast as per numpy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__int__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__long__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme-storage/pfauregi/venv/tf2.1/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "annotation_root=os.path.join(DATASET_ROOT, VAL_FOLDER, ANNOTATION_FOLDER)\n",
    "annotations_paths = return_all_files_in_folder_rec(annotation_root, [\"xml\"])\n",
    "comp_images=True\n",
    "\n",
    "print(\"Extracting groundtruth and predicted bounding boxes of \"+str(len(annotations_paths))+\" images(s).\")\n",
    "a = display(str(0)+\"/\"+str(len(annotations_paths)),display_id=True)\n",
    "all_groundtruth_bbs = []\n",
    "all_predicted_bbs = []\n",
    "all_predicted_bbs_scores = []\n",
    "for i, annotation_path in enumerate(annotations_paths[0:500]):\n",
    "    a.update(str(i+1)+\"/\"+str(len(annotations_paths)))\n",
    "    annotation = parse_annotation(annotation_path)\n",
    "    filename = annotation[\"filename\"].split(\".\")[0]\n",
    "    if IMAGE_FOLDER is None:\n",
    "        image_path = os.path.join(DATASET_ROOT, VAL_FOLDER, annotation[\"folder\"], annotation[\"filename\"])\n",
    "    else:\n",
    "        image_path = os.path.join(DATASET_ROOT, VAL_FOLDER, IMAGE_FOLDER, annotation[\"filename\"])\n",
    "    image = load_image(image_path, expand=True)\n",
    "    height, width, channels = image.shape\n",
    "    # Fetching groundtruth bounding boxes\n",
    "    groundtruth_bbs = []\n",
    "    groundtruth_bbs_colors = []\n",
    "    color_dict = {\"diatom\":(255, 0, 0), \"diatom_floue\":(0, 255, 0), \"diatom_debri\":(0, 0, 255)}\n",
    "    for obj_bb in annotation[\"objects\"]:\n",
    "        if obj_bb[\"name\"] in [\"diatom\", \"diatom_floue\",\"diatom_debri\"]:\n",
    "        #if obj_bb[\"name\"] in [\"diatom\"]:\n",
    "            groundtruth_bbs.append([obj_bb[\"ymin\"], obj_bb[\"xmin\"], obj_bb[\"ymax\"], obj_bb[\"xmax\"]])\n",
    "            groundtruth_bbs_colors.append(color_dict[obj_bb[\"name\"]])\n",
    "\n",
    "    # Fetching predicted bounding boxes\n",
    "    prediction_result = run_inference_for_single_image(model, image)\n",
    "    predicted_bbs = []\n",
    "    predicted_bbs_scores = []\n",
    "    predicted_bbs_colors = []\n",
    "    for box, score in zip(prediction_result['detection_boxes'], prediction_result['detection_scores']):\n",
    "        ymin, xmin, ymax, xmax = int(box[0]*height), int(box[1]*width), int(box[2]*height), int(box[3]*width)\n",
    "        predicted_bbs.append([ymin, xmin, ymax, xmax])\n",
    "        predicted_bbs_scores.append(score)\n",
    "        predicted_bbs_colors.append((255, 0, 0))\n",
    "    \n",
    "    all_groundtruth_bbs.extend(groundtruth_bbs)\n",
    "    all_predicted_bbs.extend(predicted_bbs)\n",
    "    all_predicted_bbs_scores.extend(predicted_bbs_scores)\n",
    "    \n",
    "    # Exporting comparison images\n",
    "    if comp_images:\n",
    "        image_prediction = draw_bbs(image, predicted_bbs, colors=predicted_bbs_colors, bbs_scores=predicted_bbs_scores, min_score=0.9, text_scale=1)\n",
    "        image_groundtruth = draw_bbs(image, groundtruth_bbs, colors=groundtruth_bbs_colors, text_scale=1)\n",
    "        # Creating and saving comparison image\n",
    "        comp_image = np.hstack((image_prediction, image_groundtruth))\n",
    "        comp_image_path = os.path.join(OUTPUT_TMP, \"images/\", filename+\"_comp.png\")\n",
    "        save_img(cv2.resize(comp_image, (0,0), fx=0.5, fy=0.5), comp_image_path, compress=5)\n",
    "        #save_img(image_groundtruth, comp_image_path)\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOC Pascal Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libPath = \"/home/pfauregi/lib/Object-Detection-Metrics/lib\"\n",
    "add_path(libPath)\n",
    "from BoundingBox import BoundingBox\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "from Evaluator import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "boundingboxes = BoundingBoxes()\n",
    "for box in all_groundtruth_bbs:\n",
    "    bb = BoundingBox(\n",
    "        filename,\n",
    "        \"diatom\",\n",
    "        box[1],\n",
    "        box[0],\n",
    "        box[3],\n",
    "        box[2],\n",
    "        CoordinatesType.Absolute,\n",
    "        bbType=BBType.GroundTruth,\n",
    "        format=BBFormat.XYX2Y2)\n",
    "    boundingboxes.addBoundingBox(bb)\n",
    "for i,box in enumerate(all_predicted_bbs):\n",
    "    bb = BoundingBox(\n",
    "                filename,\n",
    "                \"diatom\",\n",
    "                box[1],\n",
    "                box[0],\n",
    "                box[3],\n",
    "                box[2],\n",
    "                CoordinatesType.Absolute,\n",
    "                bbType=BBType.Detected,\n",
    "                classConfidence=all_predicted_bbs_scores[i],\n",
    "                format=BBFormat.XYX2Y2)\n",
    "    boundingboxes.addBoundingBox(bb)\n",
    "print(\"Finished formatting the bounding boxes!\")\n",
    "    \n",
    "# Uncomment the line below to generate images based on the bounding boxes\n",
    "\n",
    "# Create an evaluator object in order to obtain the metrics\n",
    "evaluator = Evaluator()\n",
    "# Plot Precision x Recall curve\n",
    "evaluator.PlotPrecisionRecallCurve(\n",
    "    boundingboxes,  # Object containing all bounding boxes (ground truths and detections)\n",
    "    IOUThreshold=0.3,  # IOU threshold\n",
    "    method=MethodAveragePrecision.EveryPointInterpolation,  # As the official matlab code\n",
    "    showAP=True,  # Show Average Precision in the title of the plot\n",
    "    savePath=\".\",\n",
    "    showInterpolatedPrecision=True)  # Plot the interpolated precision curve\n",
    "# Get metrics with PASCAL VOC metrics\n",
    "metricsPerClass = evaluator.GetPascalVOCMetrics(\n",
    "    boundingboxes,  # Object containing all bounding boxes (ground truths and detections)\n",
    "    IOUThreshold=0.3,  # IOU threshold\n",
    "    method=MethodAveragePrecision.EveryPointInterpolation)  # As the official matlab code\n",
    "print(\"Average precision values per class:\\n\")\n",
    "# Loop through classes to obtain their metrics\n",
    "#print(metricsPerClass)\n",
    "for mc in metricsPerClass:\n",
    "    # Get metric values per each class\n",
    "    c = mc['class']\n",
    "    precision = mc['precision']\n",
    "    recall = mc['recall']\n",
    "    average_precision = mc['AP']\n",
    "    ipre = mc['interpolated precision']\n",
    "    irec = mc['interpolated recall']\n",
    "    # Print AP per class\n",
    "    print('%s: %f' % (c, average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/brain/python/client:colab_notebook",
    "kind": "private"
   },
   "name": "object_detection_tutorial.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1LNYL6Zsn9Xlil2CVNOTsgDZQSBKeOjCh",
     "timestamp": 1566498233247
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1566488313397
    },
    {
     "file_id": "/piper/depot/google3/third_party/py/tensorflow_docs/g3doc/en/r2/tutorials/generative/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1566145894046
    },
    {
     "file_id": "1nBPoWynOV0auSIy40eQcBIk9C6YRSkI8",
     "timestamp": 1566145841085
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1556295408037
    },
    {
     "file_id": "1layerger-51XwWOwYMY_5zHaCavCeQkO",
     "timestamp": 1556214267924
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1556207836484
    },
    {
     "file_id": "1w6mqQiNV3liPIX70NOgitOlDF1_4sRMw",
     "timestamp": 1556154824101
    },
    {
     "file_id": "https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb",
     "timestamp": 1556150293326
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
