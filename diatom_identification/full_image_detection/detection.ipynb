{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBdjK2G5ywuc"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os, io\n",
    "import six.moves.urllib as urllib\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import pathlib\n",
    "\n",
    "# Personnal imports\n",
    "%run ../utils/object_detection_utils.ipynb\n",
    "%run ../utils/data_utils.ipynb\n",
    "%run ../global_variables.ipynb\n",
    "%run ./detect_variables.ipynb\n",
    "\n",
    "# Object detection API\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "utils_ops.tf = tf.compat.v1\n",
    "tf.gfile = tf.io.gfile\n",
    "\n",
    "MODEL_ROOT = os.path.join(OD_ROOT, \"ws_fine_tuning/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF-YlMl8c_bM"
   },
   "source": [
    "# Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "model1_path = os.path.join(OD_ROOT, \"ws_fine_tuning/\")\n",
    "model1 = tf.saved_model.load(os.path.join(model1_path,\"export/saved_model/\"))\n",
    "model1 = model1.signatures['serving_default']\n",
    "# Model 2\n",
    "model2_path = os.path.join(OD_ROOT, \"ws_simple_pipeline/\")\n",
    "model2 = tf.saved_model.load(os.path.join(model2_path,\"export/saved_model/\"))\n",
    "model2 = model2.signatures['serving_default']\n",
    "# Category index\n",
    "PATH_TO_LABELS = os.path.join(MODEL_ROOT,\"dataset/binary_label_map.pbtxt\")\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Computing stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbs(source, bbs, bbs_scores=None, min_score=0, colors=None, text_scale=2, title=\"\"):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    img = source.copy()\n",
    "    cv2.putText(img,  title, (70, 150), font, text_scale*4, (255,255,255), 3, cv2.LINE_AA)\n",
    "    for i, bb in enumerate(bbs):\n",
    "        color = colors[i]\n",
    "        if bbs_scores is None or bbs_scores[i]>min_score:\n",
    "            ymin, xmin, ymax, xmax = bb\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color, 4)\n",
    "            if not bbs_scores is None:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(img,  \"{:.2f}\".format(bbs_scores[i]), (xmin+5, ymin+int(text_scale*30)), font, text_scale*1, color, 3, cv2.LINE_AA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_path=\"/mnt/nvme-storage/pfauregi/training/obj_detection/eval/real_dataset/test_list.csv\"\n",
    "annotations_paths=[]\n",
    "with open(list_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    for row in reader:\n",
    "        annotations_paths.append(''.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotation_root=os.path.join(DATASET_ROOT, VAL_FOLDER, ANNOTATION_FOLDER)\n",
    "#annotations_paths = return_all_files_in_folder_rec(annotation_root, [\"xml\"])\n",
    "comp_images=True\n",
    "\n",
    "print(\"Extracting groundtruth and predicted bounding boxes of \"+str(len(annotations_paths))+\" images(s).\")\n",
    "a = display(str(0)+\"/\"+str(len(annotations_paths)),display_id=True)\n",
    "for i, annotation_path in enumerate(annotations_paths):\n",
    "    print(annotation_path)\n",
    "    a.update(str(i+1)+\"/\"+str(len(annotations_paths)))\n",
    "    annotation = parse_annotation(annotation_path)\n",
    "    filename = annotation[\"filename\"].split(\".\")[0]\n",
    "    if IMAGE_FOLDER is None:\n",
    "        print()\n",
    "        image_path = os.path.join(DATASET_ROOT, VAL_FOLDER, annotation[\"folder\"], annotation[\"filename\"])\n",
    "    else:\n",
    "        image_path = os.path.join(DATASET_ROOT, VAL_FOLDER, IMAGE_FOLDER, annotation[\"filename\"])\n",
    "    image = load_image(image_path, expand=True)\n",
    "    height, width, channels = image.shape\n",
    "    # Fetching groundtruth bounding boxes\n",
    "    groundtruth_bbs = []\n",
    "    groundtruth_bbs_colors = []\n",
    "    color_dict = {\"diatom\":(255, 0, 0), \"diatom_floue\":(0, 255, 0), \"diatom_debri\":(0, 0, 255)}\n",
    "    for obj_bb in annotation[\"objects\"]:\n",
    "        if obj_bb[\"name\"] in [\"diatom\", \"diatom_floue\",\"diatom_debri\"]:\n",
    "        #if obj_bb[\"name\"] in [\"diatom\"]:\n",
    "            groundtruth_bbs.append([obj_bb[\"ymin\"], obj_bb[\"xmin\"], obj_bb[\"ymax\"], obj_bb[\"xmax\"]])\n",
    "            groundtruth_bbs_colors.append(color_dict[obj_bb[\"name\"]])\n",
    "\n",
    "    # Model1\n",
    "    prediction_result = run_inference_for_single_image(model1, image)\n",
    "    predicted_bbs1 = []\n",
    "    predicted_bbs_scores1 = []\n",
    "    predicted_bbs_colors1 = []\n",
    "    for box, score in zip(prediction_result['detection_boxes'], prediction_result['detection_scores']):\n",
    "        ymin, xmin, ymax, xmax = int(box[0]*height), int(box[1]*width), int(box[2]*height), int(box[3]*width)\n",
    "        predicted_bbs1.append([ymin, xmin, ymax, xmax])\n",
    "        predicted_bbs_scores1.append(score)\n",
    "        predicted_bbs_colors1.append((255, 0, 0))\n",
    "        \n",
    "    # Model2\n",
    "    prediction_result = run_inference_for_single_image(model2, image)\n",
    "    predicted_bbs2 = []\n",
    "    predicted_bbs_scores2 = []\n",
    "    predicted_bbs_colors2 = []\n",
    "    for box, score in zip(prediction_result['detection_boxes'], prediction_result['detection_scores']):\n",
    "        ymin, xmin, ymax, xmax = int(box[0]*height), int(box[1]*width), int(box[2]*height), int(box[3]*width)\n",
    "        predicted_bbs2.append([ymin, xmin, ymax, xmax])\n",
    "        predicted_bbs_scores2.append(score)\n",
    "        predicted_bbs_colors2.append((255, 0, 0))\n",
    "    \n",
    "    # Exporting comparison images\n",
    "    if comp_images:\n",
    "        image_model1 = draw_bbs(image, predicted_bbs1, colors=predicted_bbs_colors1, bbs_scores=predicted_bbs_scores1, min_score=0.9, text_scale=1, title=\"Pipeline 1\")\n",
    "        image_model2 = draw_bbs(image, predicted_bbs2, colors=predicted_bbs_colors2, bbs_scores=predicted_bbs_scores2, min_score=0.9, text_scale=1, title=\"Pipeline 2\")\n",
    "        image_groundtruth = draw_bbs(image, groundtruth_bbs, colors=groundtruth_bbs_colors, text_scale=1, title=\"Goundtruth\")\n",
    "        # Creating and saving comparison image\n",
    "        comp_image = np.hstack((image_groundtruth, image_model1, image_model2))\n",
    "        comp_image_path = os.path.join(OUTPUT_TMP, \"images/\", filename+\"_comp.png\")\n",
    "        save_img(cv2.resize(comp_image, (0,0), fx=0.5, fy=0.5), comp_image_path, compress=5)\n",
    "        #save_img(image_groundtruth, comp_image_path)\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/brain/python/client:colab_notebook",
    "kind": "private"
   },
   "name": "object_detection_tutorial.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1LNYL6Zsn9Xlil2CVNOTsgDZQSBKeOjCh",
     "timestamp": 1566498233247
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1566488313397
    },
    {
     "file_id": "/piper/depot/google3/third_party/py/tensorflow_docs/g3doc/en/r2/tutorials/generative/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1566145894046
    },
    {
     "file_id": "1nBPoWynOV0auSIy40eQcBIk9C6YRSkI8",
     "timestamp": 1566145841085
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1556295408037
    },
    {
     "file_id": "1layerger-51XwWOwYMY_5zHaCavCeQkO",
     "timestamp": 1556214267924
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1556207836484
    },
    {
     "file_id": "1w6mqQiNV3liPIX70NOgitOlDF1_4sRMw",
     "timestamp": 1556154824101
    },
    {
     "file_id": "https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb",
     "timestamp": 1556150293326
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
