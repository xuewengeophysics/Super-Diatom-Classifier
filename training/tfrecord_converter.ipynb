{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.1.0\n",
      "Eager execution:  True\n",
      "Listing CPUs:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "Listing GPUs:  []\n",
      "Listing XLA_GPUs:  [PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU'), PhysicalDevice(name='/physical_device:XLA_GPU:1', device_type='XLA_GPU')]\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import io\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import PIL.Image\n",
    "import random\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "print(\"Eager execution: \", tf.executing_eagerly())\n",
    "print(\"Listing CPUs: \", tf.config.list_physical_devices('CPU'))\n",
    "print(\"Listing GPUs: \", tf.config.list_physical_devices('GPU'))\n",
    "print(\"Listing XLA_GPUs: \", tf.config.list_physical_devices('XLA_GPU'))\n",
    "\n",
    "DATA = \"./raw_dataset\"\n",
    "PNG_FOLDER = \"png_img\"\n",
    "LABELS_FOLDER = \"labels\"\n",
    "IDS_FOLDER = \"./ids\"\n",
    "TRAIN_OUTPUT_PATH = \"./dataset/train_dataset.record\"\n",
    "TEST_OUTPUT_PATH = \"./dataset/test_dataset.record\"\n",
    "IMG_TYPE = \"png\"\n",
    "PERCENTAGE_TRAIN = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(img_file, annotation, map_id):\n",
    "    ## LOADING IMAGE\n",
    "    filename = img_file[0]+\".\"+img_file[1]\n",
    "    img_path = os.path.join(DATA, PNG_FOLDER, filename)\n",
    "    with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_image_data = fid.read()\n",
    "    # Checking format\n",
    "    encoded_image_io = io.BytesIO(encoded_image_data)\n",
    "    image = PIL.Image.open(encoded_image_io)\n",
    "    if image.format != 'PNG':\n",
    "        raise ValueError('Image format not PNG')\n",
    "    # Hashing\n",
    "    key = hashlib.sha256(encoded_image_data).hexdigest()\n",
    "    \n",
    "    ## GENERAL FEATURES\n",
    "    width, height = image.size\n",
    "    image_format = IMG_TYPE.encode('utf8') # b'jpeg' or b'png'\n",
    "    ## DEFINING BOUNDING BOXES\n",
    "    xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "    xmaxs = [] # List of normalized right x coordinates in bounding box\n",
    "    ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "    ymaxs = [] # List of normalized bottom y coordinates in bounding box\n",
    "    classes_text = [] # List of string class name of bounding box (1 per box)\n",
    "    classes = [] # List of integer class id of bounding box (1 per box)\n",
    "    for bb in annotation:\n",
    "        xmins.append(bb[\"xmin\"]/width)\n",
    "        xmaxs.append(bb[\"xmax\"]/width)\n",
    "        ymins.append(bb[\"ymin\"]/height)\n",
    "        ymaxs.append(bb[\"ymax\"]/height)\n",
    "        classes_text.append(bb[\"taxon\"].encode('utf8'))\n",
    "        classes.append(map_id[bb[\"taxon\"]])\n",
    "        \n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename.encode('utf8')),\n",
    "        'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_record(img_files, output_path):\n",
    "    id_map = pickle.load(open(os.path.join(DATA, IDS_FOLDER, \"0000.pickle\"), \"rb\" ))\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "    i = 1;\n",
    "    print(\"Creating tfrecord based on \"+str(len(img_files))+\" examples. Save location: \"+output_path)\n",
    "    print(\"0 %\")\n",
    "    for image in img_files:\n",
    "        if i%(len(img_files)/5)==0:\n",
    "            print(int(i/len(img_files)*100),\"%\")\n",
    "        annotation_path = os.path.join(DATA, LABELS_FOLDER, image[0]+\".pickle\")\n",
    "        if os.path.isfile(annotation_path):\n",
    "            annotation = pickle.load(open(annotation_path, \"rb\"))\n",
    "            tf_example = create_tf_example(image, annotation, id_map)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "        else:\n",
    "            print(\"WARNING: Image \", name, \".\", extension, \" has no associated annotation file. Ignoring image.\")\n",
    "        i += 1\n",
    "    writer.close()\n",
    "    print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tfrecord based on 160 examples. Save location: ./dataset/train_dataset.record\n",
      "0 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Finished!\n",
      "Creating tfrecord based on 40 examples. Save location: ./dataset/test_dataset.record\n",
      "0 %\n",
      "20 %\n",
      "40 %\n",
      "60 %\n",
      "80 %\n",
      "100 %\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# LISTING ALL EXAMPLES FROM THE IMAGE FOLDER\n",
    "img_path = os.path.join(DATA, PNG_FOLDER)\n",
    "images = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(img_path):\n",
    "    for filename in filenames:\n",
    "        splitted = filename.split('.')\n",
    "        if len(splitted) and splitted[1].lower()==\"png\":\n",
    "            images.append([splitted[0], splitted[1]])\n",
    "random.shuffle(images)\n",
    "last_index = len(images)\n",
    "# Creating test and train dataset\n",
    "create_tf_record(images[0:int(PERCENTAGE_TRAIN*len(images))], TRAIN_OUTPUT_PATH)\n",
    "create_tf_record(images[int(PERCENTAGE_TRAIN*len(images)):len(images)], TEST_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
